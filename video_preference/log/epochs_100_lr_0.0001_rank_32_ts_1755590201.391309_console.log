Training  - bs: 1 - lr: 0.0001 - seed: 1
Epoch 0, global_step 100, average loss: 0.5665785422921181
Epoch 0, global_step 200, average loss: 0.5392356114089489
Epoch 0, global_step 300, average loss: 0.5009813409298658
Epoch 0, global_step 400, average loss: 0.5411355231329799
Epoch 0, global_step 500, average loss: 0.5229702611267567
Epoch 0, global_step 600, average loss: 0.4350141088664532
Epoch 0, global_step 700, average loss: 0.48697219878435133
Epoch 0, global_step 800, average loss: 0.47517290338873863
Epoch 0, global_step 900, average loss: 0.5606168197095394
Epoch 0, global_step 1000, average loss: 0.5351183728128671
Epoch 0, global_step 1100, average loss: 0.49307060658931734
Epoch 0, global_step 1200, average loss: 0.5128386651724577
Epoch 0, global_step 1300, average loss: 0.5311176112294197
Epoch 0, global_step 1400, average loss: 0.46141013741493225
Epoch 0, global_step 1500, average loss: 0.44268671348690986
Epoch 0, global_step 1600, average loss: 0.516663720086217
Epoch 0, global_step 1700, average loss: 0.4440747760981321
Epoch 0, global_step 1800, average loss: 0.5109595827758312
Epoch 0, global_step 1900, average loss: 0.5396872374415398
Epoch 0, global_step 2000, average loss: 0.4653850401937962
Epoch 0, global_step 2100, average loss: 0.4664495826512575
Epoch 0, global_step 2200, average loss: 0.540864957049489
Epoch 0, global_step 2300, average loss: 0.5505745586752891
Epoch 0, global_step 2400, average loss: 0.5378328360617161
Epoch 0, global_step 2500, average loss: 0.47742745190858843
Epoch 1, global_step 2600, average loss: 0.4722533092647791
Epoch 1, global_step 2700, average loss: 0.49792775586247445
Epoch 1, global_step 2800, average loss: 0.43357590705156324
Epoch 1, global_step 2900, average loss: 0.49297561749815944
Epoch 1, global_step 3000, average loss: 0.5364262211322784
Epoch 1, global_step 3100, average loss: 0.4807033590972424
Epoch 1, global_step 3200, average loss: 0.5605158325284719
Epoch 1, global_step 3300, average loss: 0.5391887578368187
Epoch 1, global_step 3400, average loss: 0.48651969626545905
Epoch 1, global_step 3500, average loss: 0.37960899755358696
Epoch 1, global_step 3600, average loss: 0.5094126547500492
Epoch 1, global_step 3700, average loss: 0.5142564161866904
Epoch 1, global_step 3800, average loss: 0.520010716766119
Epoch 1, global_step 3900, average loss: 0.4767939351499081
Epoch 1, global_step 4000, average loss: 0.5474368128180503
Epoch 1, global_step 4100, average loss: 0.49509776063263417
Epoch 1, global_step 4200, average loss: 0.5327679300308228
Epoch 1, global_step 4300, average loss: 0.4805975019931793
Epoch 1, global_step 4400, average loss: 0.5112442702800035
Epoch 1, global_step 4500, average loss: 0.5200490182638169
Epoch 1, global_step 4600, average loss: 0.5065204809606075
Epoch 1, global_step 4700, average loss: 0.4767353045940399
Epoch 1, global_step 4800, average loss: 0.44821721643209456
Epoch 1, global_step 4900, average loss: 0.44564669750630853
Epoch 1, global_step 5000, average loss: 0.433009234815836
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.6682
Best model (step 5000, average valid loss 0.7726389327435754, average valid acc 0.6682291666666667) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.7726389327435754  -  Best loss 0.7726389327435754 at step 5000
Epoch 1, global_step 5100, average loss: 0.5708848343789578
Epoch 2, global_step 5200, average loss: 0.47192382223904134
Epoch 2, global_step 5300, average loss: 0.465429153367877
Epoch 2, global_step 5400, average loss: 0.5033197040110826
Epoch 2, global_step 5500, average loss: 0.5418978530913592
Epoch 2, global_step 5600, average loss: 0.48947609938681125
Epoch 2, global_step 5700, average loss: 0.5287709023058415
Epoch 2, global_step 5800, average loss: 0.47645890653133394
Epoch 2, global_step 5900, average loss: 0.46150092259049413
Epoch 2, global_step 6000, average loss: 0.4832363511621952
Epoch 2, global_step 6100, average loss: 0.5204411064088345
Epoch 2, global_step 6200, average loss: 0.480149577409029
Epoch 2, global_step 6300, average loss: 0.45704093024134634
Epoch 2, global_step 6400, average loss: 0.5161344735696912
Epoch 2, global_step 6500, average loss: 0.5105448281764984
Epoch 2, global_step 6600, average loss: 0.44671239718794825
Epoch 2, global_step 6700, average loss: 0.4354472117871046
Epoch 2, global_step 6800, average loss: 0.49751853831112386
Epoch 2, global_step 6900, average loss: 0.5681155776977539
Epoch 2, global_step 7000, average loss: 0.534906443953514
Epoch 2, global_step 7100, average loss: 0.5046798286587
Epoch 2, global_step 7200, average loss: 0.5614787450432778
Epoch 2, global_step 7300, average loss: 0.45781727820634843
Epoch 2, global_step 7400, average loss: 0.4681143188849092
Epoch 2, global_step 7500, average loss: 0.5271899427846074
Epoch 2, global_step 7600, average loss: 0.48262575566768645
Epoch 3, global_step 7700, average loss: 0.45806189827620986
Epoch 3, global_step 7800, average loss: 0.4296387854963541
Epoch 3, global_step 7900, average loss: 0.5665210136026144
Epoch 3, global_step 8000, average loss: 0.532450340539217
Epoch 3, global_step 8100, average loss: 0.488918197453022
Epoch 3, global_step 8200, average loss: 0.488797383159399
Epoch 3, global_step 8300, average loss: 0.4934582434594631
Epoch 3, global_step 8400, average loss: 0.47749372385442257
Epoch 3, global_step 8500, average loss: 0.5060508559644222
Epoch 3, global_step 8600, average loss: 0.48488017842173575
Epoch 3, global_step 8700, average loss: 0.40057122960686686
Epoch 3, global_step 8800, average loss: 0.5522807621210813
Epoch 3, global_step 8900, average loss: 0.5461657017469406
Epoch 3, global_step 9000, average loss: 0.4509253521263599
Epoch 3, global_step 9100, average loss: 0.5376111201569438
Epoch 3, global_step 9200, average loss: 0.5044893768429756
Epoch 3, global_step 9300, average loss: 0.4530425438284874
Epoch 3, global_step 9400, average loss: 0.4284273715689778
Epoch 3, global_step 9500, average loss: 0.5038995157927275
Epoch 3, global_step 9600, average loss: 0.47240325942635536
Epoch 3, global_step 9700, average loss: 0.47688909888267517
Epoch 3, global_step 9800, average loss: 0.5716996814310551
Epoch 3, global_step 9900, average loss: 0.43873290583491326
Epoch 3, global_step 10000, average loss: 0.5207545837014913
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.6760
Best model (step 10000, average valid loss 0.7592479780490976, average valid acc 0.6760416666666667) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.7592479780490976  -  Best loss 0.7592479780490976 at step 10000
Epoch 3, global_step 10100, average loss: 0.5213959090784193
Epoch 3, global_step 10200, average loss: 0.4914663880690932
Epoch 4, global_step 10300, average loss: 0.5371429528668523
Epoch 4, global_step 10400, average loss: 0.49797527987509965
Epoch 4, global_step 10500, average loss: 0.46033032760024073
Epoch 4, global_step 10600, average loss: 0.4714732184074819
Epoch 4, global_step 10700, average loss: 0.48407708073034883
Epoch 4, global_step 10800, average loss: 0.48297522604465487
Epoch 4, global_step 10900, average loss: 0.5778965500742197
Epoch 4, global_step 11000, average loss: 0.46012590147554877
Epoch 4, global_step 11100, average loss: 0.47801843214780093
Epoch 4, global_step 11200, average loss: 0.47358684916049243
Epoch 4, global_step 11300, average loss: 0.4971234579384327
Epoch 4, global_step 11400, average loss: 0.5047351472079754
Epoch 4, global_step 11500, average loss: 0.48896960489451885
Epoch 4, global_step 11600, average loss: 0.5240978534147144
Epoch 4, global_step 11700, average loss: 0.4970862026512623
Epoch 4, global_step 11800, average loss: 0.5123051577433944
Epoch 4, global_step 11900, average loss: 0.481260828115046
Epoch 4, global_step 12000, average loss: 0.4900217113643885
Epoch 4, global_step 12100, average loss: 0.41505503371357916
Epoch 4, global_step 12200, average loss: 0.4453022060915828
Epoch 4, global_step 12300, average loss: 0.5085715575516224
Epoch 4, global_step 12400, average loss: 0.5212397260218858
Epoch 4, global_step 12500, average loss: 0.5019226395711303
Epoch 4, global_step 12600, average loss: 0.44556859858334064
Epoch 4, global_step 12700, average loss: 0.5064089554175735
Epoch 4, global_step 12800, average loss: 0.46300602447241546
Epoch 5, global_step 12900, average loss: 0.4726877503842115
Epoch 5, global_step 13000, average loss: 0.5042723800241947
Epoch 5, global_step 13100, average loss: 0.4567397050000727
Epoch 5, global_step 13200, average loss: 0.4620106166508049
Epoch 5, global_step 13300, average loss: 0.4860180060379207
Epoch 5, global_step 13400, average loss: 0.4418898781388998
Epoch 5, global_step 13500, average loss: 0.5236869664117694
Epoch 5, global_step 13600, average loss: 0.468544597402215
Epoch 5, global_step 13700, average loss: 0.44065445125103
Epoch 5, global_step 13800, average loss: 0.5229503821954131
Epoch 5, global_step 13900, average loss: 0.476943374350667
Epoch 5, global_step 14000, average loss: 0.47213718101382257
Epoch 5, global_step 14100, average loss: 0.4347384878993034
Epoch 5, global_step 14200, average loss: 0.4547922300547361
Epoch 5, global_step 14300, average loss: 0.45207594506442544
Epoch 5, global_step 14400, average loss: 0.5150421081483364
Epoch 5, global_step 14500, average loss: 0.46840590715408326
Epoch 5, global_step 14600, average loss: 0.4593157135695219
Epoch 5, global_step 14700, average loss: 0.47911573998630047
Epoch 5, global_step 14800, average loss: 0.48718392677605155
Epoch 5, global_step 14900, average loss: 0.504606118351221
Epoch 5, global_step 15000, average loss: 0.49525247113779186
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.6797
Best model (step 15000, average valid loss 0.6989496899099322, average valid acc 0.6796875) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.6989496899099322  -  Best loss 0.6989496899099322 at step 15000
Epoch 5, global_step 15100, average loss: 0.47393424063920975
Epoch 5, global_step 15200, average loss: 0.43262230437248944
Epoch 5, global_step 15300, average loss: 0.42633082827553154
Epoch 6, global_step 15400, average loss: 0.5159451021812856
Epoch 6, global_step 15500, average loss: 0.4962575905025005
Epoch 6, global_step 15600, average loss: 0.47465580321848394
Epoch 6, global_step 15700, average loss: 0.4679366610199213
Epoch 6, global_step 15800, average loss: 0.4625605530291796
Epoch 6, global_step 15900, average loss: 0.5284741732850671
Epoch 6, global_step 16000, average loss: 0.43205921560525895
Epoch 6, global_step 16100, average loss: 0.45118079718202353
Epoch 6, global_step 16200, average loss: 0.44036439201794564
Epoch 6, global_step 16300, average loss: 0.4100228602089919
Epoch 6, global_step 16400, average loss: 0.4933468468906358
Epoch 6, global_step 16500, average loss: 0.4292069096490741
Epoch 6, global_step 16600, average loss: 0.43557870004326105
Epoch 6, global_step 16700, average loss: 0.3667059046402574
Epoch 6, global_step 16800, average loss: 0.40646800346672535
Epoch 6, global_step 16900, average loss: 0.48971984716132283
Epoch 6, global_step 17000, average loss: 0.4751940006017685
Epoch 6, global_step 17100, average loss: 0.43677860368043187
Epoch 6, global_step 17200, average loss: 0.40046581711620094
Epoch 6, global_step 17300, average loss: 0.48161833789199593
Epoch 6, global_step 17400, average loss: 0.47185524858534333
Epoch 6, global_step 17500, average loss: 0.43673542261123655
Epoch 6, global_step 17600, average loss: 0.3954700089246035
Epoch 6, global_step 17700, average loss: 0.48793346708640456
Epoch 6, global_step 17800, average loss: 0.44872152410447597
Epoch 6, global_step 17900, average loss: 0.4408750108629465
Epoch 7, global_step 18000, average loss: 0.5435764586180448
Epoch 7, global_step 18100, average loss: 0.42275399461388585
Epoch 7, global_step 18200, average loss: 0.38960719922557474
Epoch 7, global_step 18300, average loss: 0.4585612258687615
Epoch 7, global_step 18400, average loss: 0.419087251201272
Epoch 7, global_step 18500, average loss: 0.43459883850067854
Epoch 7, global_step 18600, average loss: 0.4438565934076905
Epoch 7, global_step 18700, average loss: 0.3913673734292388
Epoch 7, global_step 18800, average loss: 0.4867059717513621
Epoch 7, global_step 18900, average loss: 0.43683730429038403
Epoch 7, global_step 19000, average loss: 0.4002459256723523
Epoch 7, global_step 19100, average loss: 0.4432100917864591
Epoch 7, global_step 19200, average loss: 0.4665125430747867
Epoch 7, global_step 19300, average loss: 0.49517090582288803
Epoch 7, global_step 19400, average loss: 0.4395439833309501
Epoch 7, global_step 19500, average loss: 0.41202099483460186
Epoch 7, global_step 19600, average loss: 0.40818754605948926
Epoch 7, global_step 19700, average loss: 0.4260756554827094
Epoch 7, global_step 19800, average loss: 0.4119858980178833
Epoch 7, global_step 19900, average loss: 0.44832782899960877
Epoch 7, global_step 20000, average loss: 0.42791971504688264
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.7625
Best model (step 20000, average valid loss 0.5288701920508174, average valid acc 0.7625) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.5288701920508174  -  Best loss 0.5288701920508174 at step 20000
Epoch 7, global_step 20100, average loss: 0.429954890049994
Epoch 7, global_step 20200, average loss: 0.42593440756201745
Epoch 7, global_step 20300, average loss: 0.40396817464381457
Epoch 7, global_step 20400, average loss: 0.43907857056707145
Epoch 8, global_step 20500, average loss: 0.40316856402903795
Epoch 8, global_step 20600, average loss: 0.435986502058804
Epoch 8, global_step 20700, average loss: 0.388803425328806
Epoch 8, global_step 20800, average loss: 0.4120401596277952
Epoch 8, global_step 20900, average loss: 0.3792656593164429
Epoch 8, global_step 21000, average loss: 0.41024718788452447
Epoch 8, global_step 21100, average loss: 0.40150152910500764
Epoch 8, global_step 21200, average loss: 0.3630853485967964
Epoch 8, global_step 21300, average loss: 0.41116708859801293
Epoch 8, global_step 21400, average loss: 0.4110818387940526
Epoch 8, global_step 21500, average loss: 0.43108117322437467
Epoch 8, global_step 21600, average loss: 0.4056534165376797
Epoch 8, global_step 21700, average loss: 0.43657339200377465
Epoch 8, global_step 21800, average loss: 0.3924895827379078
Epoch 8, global_step 21900, average loss: 0.31678645708598197
Epoch 8, global_step 22000, average loss: 0.3455842054123059
Epoch 8, global_step 22100, average loss: 0.4248539805831388
Epoch 8, global_step 22200, average loss: 0.44125603811815384
Epoch 8, global_step 22300, average loss: 0.41094389364123346
Epoch 8, global_step 22400, average loss: 0.39791562804952263
Epoch 8, global_step 22500, average loss: 0.40669079313986
Epoch 8, global_step 22600, average loss: 0.45855843578465283
Epoch 8, global_step 22700, average loss: 0.45138405192643405
Epoch 8, global_step 22800, average loss: 0.4438858913630247
Epoch 8, global_step 22900, average loss: 0.3986081453599036
Epoch 8, global_step 23000, average loss: 0.33759560209698974
Epoch 9, global_step 23100, average loss: 0.34355706970207395
Epoch 9, global_step 23200, average loss: 0.38246164463460447
Epoch 9, global_step 23300, average loss: 0.4496622945740819
Epoch 9, global_step 23400, average loss: 0.35760506577789786
Epoch 9, global_step 23500, average loss: 0.349595968388021
Epoch 9, global_step 23600, average loss: 0.37984838377218694
Epoch 9, global_step 23700, average loss: 0.39449605411849914
Epoch 9, global_step 23800, average loss: 0.3014131373446435
Epoch 9, global_step 23900, average loss: 0.3880226836167276
Epoch 9, global_step 24000, average loss: 0.39259789429372177
Epoch 9, global_step 24100, average loss: 0.35303289759904144
Epoch 9, global_step 24200, average loss: 0.3100360720884055
Epoch 9, global_step 24300, average loss: 0.4159531771205366
Epoch 9, global_step 24400, average loss: 0.3778645159676671
Epoch 9, global_step 24500, average loss: 0.41153610941022634
Epoch 9, global_step 24600, average loss: 0.3413369445782155
Epoch 9, global_step 24700, average loss: 0.3364431712916121
Epoch 9, global_step 24800, average loss: 0.3745657261041924
Epoch 9, global_step 24900, average loss: 0.3546555854845792
Epoch 9, global_step 25000, average loss: 0.31410848975880074
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.7964
Best model (step 25000, average valid loss 0.4896905599405727, average valid acc 0.7963541666666667) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.4896905599405727  -  Best loss 0.4896905599405727 at step 25000
Epoch 9, global_step 25100, average loss: 0.365587117690593
Epoch 9, global_step 25200, average loss: 0.45456267638597636
Epoch 9, global_step 25300, average loss: 0.3900763590075076
Epoch 9, global_step 25400, average loss: 0.4279742639651522
Epoch 9, global_step 25500, average loss: 0.39956077105365695
Epoch 9, global_step 25600, average loss: 0.3776533721201122
Epoch 10, global_step 25700, average loss: 0.30456039890646935
Epoch 10, global_step 25800, average loss: 0.3668705220799893
Epoch 10, global_step 25900, average loss: 0.380485215340741
Epoch 10, global_step 26000, average loss: 0.3717396561289206
Epoch 10, global_step 26100, average loss: 0.3552407349413261
Epoch 10, global_step 26200, average loss: 0.3767497264011763
Epoch 10, global_step 26300, average loss: 0.4059334082133137
Epoch 10, global_step 26400, average loss: 0.30257416777312757
Epoch 10, global_step 26500, average loss: 0.3385712567484006
Epoch 10, global_step 26600, average loss: 0.3236108301859349
Epoch 10, global_step 26700, average loss: 0.3497670057369396
Epoch 10, global_step 26800, average loss: 0.38733340345788747
Epoch 10, global_step 26900, average loss: 0.3378726041037589
Epoch 10, global_step 27000, average loss: 0.42240488635143264
Epoch 10, global_step 27100, average loss: 0.3591861953958869
Epoch 10, global_step 27200, average loss: 0.27711726861889474
Epoch 10, global_step 27300, average loss: 0.4183012581965886
Epoch 10, global_step 27400, average loss: 0.338181750344811
Epoch 10, global_step 27500, average loss: 0.3918238474521786
Epoch 10, global_step 27600, average loss: 0.39103344867005946
Epoch 10, global_step 27700, average loss: 0.3861094853375107
Epoch 10, global_step 27800, average loss: 0.3229401332559064
Epoch 10, global_step 27900, average loss: 0.3442195508489385
Epoch 10, global_step 28000, average loss: 0.3387479352939408
Epoch 10, global_step 28100, average loss: 0.28122572869993745
Epoch 11, global_step 28200, average loss: 0.3631466027162969
Epoch 11, global_step 28300, average loss: 0.3006705422978848
Epoch 11, global_step 28400, average loss: 0.3187873905315064
Epoch 11, global_step 28500, average loss: 0.3377279656124301
Epoch 11, global_step 28600, average loss: 0.3362535341642797
Epoch 11, global_step 28700, average loss: 0.295572027573362
Epoch 11, global_step 28800, average loss: 0.3060167076694779
Epoch 11, global_step 28900, average loss: 0.4303816006425768
Epoch 11, global_step 29000, average loss: 0.32865500495303424
Epoch 11, global_step 29100, average loss: 0.4185935919708572
Epoch 11, global_step 29200, average loss: 0.377296374309808
Epoch 11, global_step 29300, average loss: 0.330729806534946
Epoch 11, global_step 29400, average loss: 0.373474697410129
Epoch 11, global_step 29500, average loss: 0.4051936047524214
Epoch 11, global_step 29600, average loss: 0.31444198936689643
Epoch 11, global_step 29700, average loss: 0.29688458450138566
Epoch 11, global_step 29800, average loss: 0.31775218221824614
Epoch 11, global_step 29900, average loss: 0.33841168302693403
Epoch 11, global_step 30000, average loss: 0.2967831295344513
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8016
Best model (step 30000, average valid loss 0.4574354756374305, average valid acc 0.8015625) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.4574354756374305  -  Best loss 0.4574354756374305 at step 30000
Epoch 11, global_step 30100, average loss: 0.36392980998905844
Epoch 11, global_step 30200, average loss: 0.32028663718840106
Epoch 11, global_step 30300, average loss: 0.2744674904528074
Epoch 11, global_step 30400, average loss: 0.3536337643388833
Epoch 11, global_step 30500, average loss: 0.23457218088326046
Epoch 11, global_step 30600, average loss: 0.39162831154011657
Epoch 11, global_step 30700, average loss: 0.3719833632837981
Epoch 12, global_step 30800, average loss: 0.3756801033159718
Epoch 12, global_step 30900, average loss: 0.34061858381144705
Epoch 12, global_step 31000, average loss: 0.32177770940121264
Epoch 12, global_step 31100, average loss: 0.33702233352116306
Epoch 12, global_step 31200, average loss: 0.26448665881936906
Epoch 12, global_step 31300, average loss: 0.33703662041341886
Epoch 12, global_step 31400, average loss: 0.2714578291994985
Epoch 12, global_step 31500, average loss: 0.3561913777812151
Epoch 12, global_step 31600, average loss: 0.35447837505606006
Epoch 12, global_step 31700, average loss: 0.3637478039250709
Epoch 12, global_step 31800, average loss: 0.2741811550129205
Epoch 12, global_step 31900, average loss: 0.2700239013088867
Epoch 12, global_step 32000, average loss: 0.2903354025055887
Epoch 12, global_step 32100, average loss: 0.39282229111297057
Epoch 12, global_step 32200, average loss: 0.30587301339546685
Epoch 12, global_step 32300, average loss: 0.3720614038000349
Epoch 12, global_step 32400, average loss: 0.35282438214868306
Epoch 12, global_step 32500, average loss: 0.30008401558501646
Epoch 12, global_step 32600, average loss: 0.376111407042481
Epoch 12, global_step 32700, average loss: 0.33682263575959953
Epoch 12, global_step 32800, average loss: 0.32375185235985554
Epoch 12, global_step 32900, average loss: 0.3000318710645661
Epoch 12, global_step 33000, average loss: 0.2879499507654691
Epoch 12, global_step 33100, average loss: 0.352325366641162
Epoch 12, global_step 33200, average loss: 0.2807217987300828
Epoch 13, global_step 33300, average loss: 0.25125894001335836
Epoch 13, global_step 33400, average loss: 0.24194989471463488
Epoch 13, global_step 33500, average loss: 0.2980234726553317
Epoch 13, global_step 33600, average loss: 0.3146460625337204
Epoch 13, global_step 33700, average loss: 0.33716757909511214
Epoch 13, global_step 33800, average loss: 0.3042304014484398
Epoch 13, global_step 33900, average loss: 0.3587887906702235
Epoch 13, global_step 34000, average loss: 0.2726278423558688
Epoch 13, global_step 34100, average loss: 0.27010412838775666
Epoch 13, global_step 34200, average loss: 0.2898671773599926
Epoch 13, global_step 34300, average loss: 0.3188951299180917
Epoch 13, global_step 34400, average loss: 0.28883255263615865
Epoch 13, global_step 34500, average loss: 0.3505299902713159
Epoch 13, global_step 34600, average loss: 0.30681434330588675
Epoch 13, global_step 34700, average loss: 0.3024479576840531
Epoch 13, global_step 34800, average loss: 0.3255775167862885
Epoch 13, global_step 34900, average loss: 0.3672167069045827
Epoch 13, global_step 35000, average loss: 0.29627458669478074
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.7896
Valid loss 0.4407688138697267  -  Best loss 0.4574354756374305 at step 30000
Epoch 13, global_step 35100, average loss: 0.2773646566667594
Epoch 13, global_step 35200, average loss: 0.2931145297718467
Epoch 13, global_step 35300, average loss: 0.3179247328400379
Epoch 13, global_step 35400, average loss: 0.3458451005749521
Epoch 13, global_step 35500, average loss: 0.3372706835530698
Epoch 13, global_step 35600, average loss: 0.31611226111650464
Epoch 13, global_step 35700, average loss: 0.31405586808687075
Epoch 13, global_step 35800, average loss: 0.26960199990891853
Epoch 14, global_step 35900, average loss: 0.24889323595212773
Epoch 14, global_step 36000, average loss: 0.3084263484319672
Epoch 14, global_step 36100, average loss: 0.31084240797441454
Epoch 14, global_step 36200, average loss: 0.35770445175818166
Epoch 14, global_step 36300, average loss: 0.3153998275636695
Epoch 14, global_step 36400, average loss: 0.2934242867201101
Epoch 14, global_step 36500, average loss: 0.2647399325051811
Epoch 14, global_step 36600, average loss: 0.3129665968373592
Epoch 14, global_step 36700, average loss: 0.29875132998276965
Epoch 14, global_step 36800, average loss: 0.2622245516971452
Epoch 14, global_step 36900, average loss: 0.41665520267415557
Epoch 14, global_step 37000, average loss: 0.25692803723737595
Epoch 14, global_step 37100, average loss: 0.3094134419746115
Epoch 14, global_step 37200, average loss: 0.24159572836186272
Epoch 14, global_step 37300, average loss: 0.2703153954830486
Epoch 14, global_step 37400, average loss: 0.324141083813156
Epoch 14, global_step 37500, average loss: 0.3369845870230347
Epoch 14, global_step 37600, average loss: 0.34831620009383185
Epoch 14, global_step 37700, average loss: 0.2983955809258623
Epoch 14, global_step 37800, average loss: 0.24613194811878203
Epoch 14, global_step 37900, average loss: 0.282658147734237
Epoch 14, global_step 38000, average loss: 0.22513238231847935
Epoch 14, global_step 38100, average loss: 0.2509759313450195
Epoch 14, global_step 38200, average loss: 0.3576025476543873
Epoch 14, global_step 38300, average loss: 0.2842355341516668
Epoch 14, global_step 38400, average loss: 0.35423781862162285
Epoch 15, global_step 38500, average loss: 0.3447910474872333
Epoch 15, global_step 38600, average loss: 0.24390572793548926
Epoch 15, global_step 38700, average loss: 0.24999452140415088
Epoch 15, global_step 38800, average loss: 0.22268158263992519
Epoch 15, global_step 38900, average loss: 0.25637205015693326
Epoch 15, global_step 39000, average loss: 0.26855514998380386
Epoch 15, global_step 39100, average loss: 0.30560043051082175
Epoch 15, global_step 39200, average loss: 0.2780664414749481
Epoch 15, global_step 39300, average loss: 0.28273518078698545
Epoch 15, global_step 39400, average loss: 0.34087003836917573
Epoch 15, global_step 39500, average loss: 0.3916316234176338
Epoch 15, global_step 39600, average loss: 0.36264216794399545
Epoch 15, global_step 39700, average loss: 0.25070130873238666
Epoch 15, global_step 39800, average loss: 0.33971810850549444
Epoch 15, global_step 39900, average loss: 0.22755309090513037
Epoch 15, global_step 40000, average loss: 0.2274606563825364
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8281
Best model (step 40000, average valid loss 0.464669758829001, average valid acc 0.828125) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.464669758829001  -  Best loss 0.464669758829001 at step 40000
Epoch 15, global_step 40100, average loss: 0.25125202583498324
Epoch 15, global_step 40200, average loss: 0.2743941137366346
Epoch 15, global_step 40300, average loss: 0.2491275655251229
Epoch 15, global_step 40400, average loss: 0.2540570389060304
Epoch 15, global_step 40500, average loss: 0.34670401515322735
Epoch 15, global_step 40600, average loss: 0.29264258727867853
Epoch 15, global_step 40700, average loss: 0.2673897482881148
Epoch 15, global_step 40800, average loss: 0.29306879662792196
Epoch 15, global_step 40900, average loss: 0.2723284783755662
Epoch 16, global_step 41000, average loss: 0.3266490035097377
Epoch 16, global_step 41100, average loss: 0.2732593723767059
Epoch 16, global_step 41200, average loss: 0.322186997823228
Epoch 16, global_step 41300, average loss: 0.2516426936678908
Epoch 16, global_step 41400, average loss: 0.26377467562306267
Epoch 16, global_step 41500, average loss: 0.2572388609398331
Epoch 16, global_step 41600, average loss: 0.2784574088336376
Epoch 16, global_step 41700, average loss: 0.23950651059109077
Epoch 16, global_step 41800, average loss: 0.26966935899996314
Epoch 16, global_step 41900, average loss: 0.27532292153540766
Epoch 16, global_step 42000, average loss: 0.264240555492579
Epoch 16, global_step 42100, average loss: 0.2809282792148588
Epoch 16, global_step 42200, average loss: 0.28528210473887156
Epoch 16, global_step 42300, average loss: 0.29323820855992383
Epoch 16, global_step 42400, average loss: 0.32908414960082155
Epoch 16, global_step 42500, average loss: 0.2472311354195699
Epoch 16, global_step 42600, average loss: 0.314073857285548
Epoch 16, global_step 42700, average loss: 0.3493553896693629
Epoch 16, global_step 42800, average loss: 0.27464168494567276
Epoch 16, global_step 42900, average loss: 0.25859741569947803
Epoch 16, global_step 43000, average loss: 0.30354092841334934
Epoch 16, global_step 43100, average loss: 0.2479382897692267
Epoch 16, global_step 43200, average loss: 0.24759110683422478
Epoch 16, global_step 43300, average loss: 0.2722857971146732
Epoch 16, global_step 43400, average loss: 0.22399727068346692
Epoch 16, global_step 43500, average loss: 0.3213052785367108
Epoch 17, global_step 43600, average loss: 0.3021565053856466
Epoch 17, global_step 43700, average loss: 0.23599658289007494
Epoch 17, global_step 43800, average loss: 0.25025485035977907
Epoch 17, global_step 43900, average loss: 0.2652898824424483
Epoch 17, global_step 44000, average loss: 0.21707473470945843
Epoch 17, global_step 44100, average loss: 0.24166623774170148
Epoch 17, global_step 44200, average loss: 0.1938676565784408
Epoch 17, global_step 44300, average loss: 0.22177805447747231
Epoch 17, global_step 44400, average loss: 0.2811777811116917
Epoch 17, global_step 44500, average loss: 0.25113872616897426
Epoch 17, global_step 44600, average loss: 0.28506072282165407
Epoch 17, global_step 44700, average loss: 0.33639849516548564
Epoch 17, global_step 44800, average loss: 0.3095072969868488
Epoch 17, global_step 44900, average loss: 0.27137163781619167
Epoch 17, global_step 45000, average loss: 0.23980305418022907
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8281
Valid loss 0.3700341558788807  -  Best loss 0.464669758829001 at step 40000
Epoch 17, global_step 45100, average loss: 0.2718202826521883
Epoch 17, global_step 45200, average loss: 0.2573147008611704
Epoch 17, global_step 45300, average loss: 0.28045069488587615
Epoch 17, global_step 45400, average loss: 0.2799553115994786
Epoch 17, global_step 45500, average loss: 0.2655316826944181
Epoch 17, global_step 45600, average loss: 0.22180253192098462
Epoch 17, global_step 45700, average loss: 0.30497472314338664
Epoch 17, global_step 45800, average loss: 0.2091417519163224
Epoch 17, global_step 45900, average loss: 0.3472355875570793
Epoch 17, global_step 46000, average loss: 0.23430766606616088
Epoch 18, global_step 46100, average loss: 0.32121107013066647
Epoch 18, global_step 46200, average loss: 0.20229823501082136
Epoch 18, global_step 46300, average loss: 0.2487873335619588
Epoch 18, global_step 46400, average loss: 0.2800607527445027
Epoch 18, global_step 46500, average loss: 0.20516107825707877
Epoch 18, global_step 46600, average loss: 0.2362057723544058
Epoch 18, global_step 46700, average loss: 0.2406730152431919
Epoch 18, global_step 46800, average loss: 0.2127368414729426
Epoch 18, global_step 46900, average loss: 0.26191827607981394
Epoch 18, global_step 47000, average loss: 0.23622912330723922
Epoch 18, global_step 47100, average loss: 0.16901958212569299
Epoch 18, global_step 47200, average loss: 0.23665463513061696
Epoch 18, global_step 47300, average loss: 0.1861024288797853
Epoch 18, global_step 47400, average loss: 0.3150003056089918
Epoch 18, global_step 47500, average loss: 0.2392228278177572
Epoch 18, global_step 47600, average loss: 0.3115981461768388
Epoch 18, global_step 47700, average loss: 0.27138678617477124
Epoch 18, global_step 47800, average loss: 0.26639072670761377
Epoch 18, global_step 47900, average loss: 0.24859330156719806
Epoch 18, global_step 48000, average loss: 0.2930014806308827
Epoch 18, global_step 48100, average loss: 0.2843976946949988
Epoch 18, global_step 48200, average loss: 0.2556252094157753
Epoch 18, global_step 48300, average loss: 0.27276213690725853
Epoch 18, global_step 48400, average loss: 0.27009159601002464
Epoch 18, global_step 48500, average loss: 0.29456636054037516
Epoch 18, global_step 48600, average loss: 0.26630655468186887
Epoch 19, global_step 48700, average loss: 0.2627708501763846
Epoch 19, global_step 48800, average loss: 0.3110817604103067
Epoch 19, global_step 48900, average loss: 0.17407404858517112
Epoch 19, global_step 49000, average loss: 0.2743872884189477
Epoch 19, global_step 49100, average loss: 0.2661430561835004
Epoch 19, global_step 49200, average loss: 0.331786915476805
Epoch 19, global_step 49300, average loss: 0.21484054469266994
Epoch 19, global_step 49400, average loss: 0.20172200404911564
Epoch 19, global_step 49500, average loss: 0.24201597476141615
Epoch 19, global_step 49600, average loss: 0.230494746643526
Epoch 19, global_step 49700, average loss: 0.23467904789024033
Epoch 19, global_step 49800, average loss: 0.24624985896040016
Epoch 19, global_step 49900, average loss: 0.21155079260879575
Epoch 19, global_step 50000, average loss: 0.14301196180967962
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8411
Best model (step 50000, average valid loss 0.3795115383913796, average valid acc 0.8411458333333334) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.3795115383913796  -  Best loss 0.3795115383913796 at step 50000
Epoch 19, global_step 50100, average loss: 0.14201398617729866
Epoch 19, global_step 50200, average loss: 0.21338778887071386
Epoch 19, global_step 50300, average loss: 0.2669797637975353
Epoch 19, global_step 50400, average loss: 0.1873677120807042
Epoch 19, global_step 50500, average loss: 0.2373126054682507
Epoch 19, global_step 50600, average loss: 0.2769981573583209
Epoch 19, global_step 50700, average loss: 0.2615489822423115
Epoch 19, global_step 50800, average loss: 0.3330367405842844
Epoch 19, global_step 50900, average loss: 0.17037728900631918
Epoch 19, global_step 51000, average loss: 0.24848217964205105
Epoch 19, global_step 51100, average loss: 0.3548760556758498
Epoch 19, global_step 51200, average loss: 0.2571296704854467
Epoch 20, global_step 51300, average loss: 0.19783221872530704
Epoch 20, global_step 51400, average loss: 0.2570535319650662
Epoch 20, global_step 51500, average loss: 0.23484560186087036
Epoch 20, global_step 51600, average loss: 0.15174668521780404
Epoch 20, global_step 51700, average loss: 0.20599873365550592
Epoch 20, global_step 51800, average loss: 0.22080626556769858
Epoch 20, global_step 51900, average loss: 0.2732378972009246
Epoch 20, global_step 52000, average loss: 0.2504308330912681
Epoch 20, global_step 52100, average loss: 0.31738929466431726
Epoch 20, global_step 52200, average loss: 0.25499868729024455
Epoch 20, global_step 52300, average loss: 0.2160876424649905
Epoch 20, global_step 52400, average loss: 0.24009143546372796
Epoch 20, global_step 52500, average loss: 0.32459652780435133
Epoch 20, global_step 52600, average loss: 0.24466508322220762
Epoch 20, global_step 52700, average loss: 0.23176717771926633
Epoch 20, global_step 52800, average loss: 0.2232120646497424
Epoch 20, global_step 52900, average loss: 0.18902380303861718
Epoch 20, global_step 53000, average loss: 0.24237393159222848
Epoch 20, global_step 53100, average loss: 0.22564180216781096
Epoch 20, global_step 53200, average loss: 0.2523540734763083
Epoch 20, global_step 53300, average loss: 0.24711776042473502
Epoch 20, global_step 53400, average loss: 0.23469525531043472
Epoch 20, global_step 53500, average loss: 0.19761950587264437
Epoch 20, global_step 53600, average loss: 0.17002658072156918
Epoch 20, global_step 53700, average loss: 0.1395324382009494
save checkpoint at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint/epoch20
Epoch 21, global_step 53800, average loss: 0.22805185454100865
Epoch 21, global_step 53900, average loss: 0.20913115653631395
Epoch 21, global_step 54000, average loss: 0.25648044678979204
Epoch 21, global_step 54100, average loss: 0.24924710594517818
Epoch 21, global_step 54200, average loss: 0.17555614574845094
Epoch 21, global_step 54300, average loss: 0.2821749239800556
Epoch 21, global_step 54400, average loss: 0.24877396465257334
Epoch 21, global_step 54500, average loss: 0.2779798919046152
Epoch 21, global_step 54600, average loss: 0.21187706670109038
Epoch 21, global_step 54700, average loss: 0.19737237253022613
Epoch 21, global_step 54800, average loss: 0.2415012079166263
Epoch 21, global_step 54900, average loss: 0.2221216140962133
Epoch 21, global_step 55000, average loss: 0.27522249921545155
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8313
Valid loss 0.37452665386056483  -  Best loss 0.3795115383913796 at step 50000
Epoch 21, global_step 55100, average loss: 0.269348004802996
Epoch 21, global_step 55200, average loss: 0.25345627151898953
Epoch 21, global_step 55300, average loss: 0.22092632662664982
Epoch 21, global_step 55400, average loss: 0.18470681156530191
Epoch 21, global_step 55500, average loss: 0.25077914461209727
Epoch 21, global_step 55600, average loss: 0.2575718420271005
Epoch 21, global_step 55700, average loss: 0.19445732497300924
Epoch 21, global_step 55800, average loss: 0.23343617306982195
Epoch 21, global_step 55900, average loss: 0.257554389274228
Epoch 21, global_step 56000, average loss: 0.28588175311979286
Epoch 21, global_step 56100, average loss: 0.19199909837276208
Epoch 21, global_step 56200, average loss: 0.19759185626342515
Epoch 21, global_step 56300, average loss: 0.23076913680404687
Epoch 22, global_step 56400, average loss: 0.25905808442090345
Epoch 22, global_step 56500, average loss: 0.24464319752740266
Epoch 22, global_step 56600, average loss: 0.23797789214157092
Epoch 22, global_step 56700, average loss: 0.2962613414844236
Epoch 22, global_step 56800, average loss: 0.2240291975099535
Epoch 22, global_step 56900, average loss: 0.2309631441712554
Epoch 22, global_step 57000, average loss: 0.2794182319378888
Epoch 22, global_step 57100, average loss: 0.1969262794997485
Epoch 22, global_step 57200, average loss: 0.24623845926682406
Epoch 22, global_step 57300, average loss: 0.16516995916670565
Epoch 22, global_step 57400, average loss: 0.1471670945773076
Epoch 22, global_step 57500, average loss: 0.2256803051939278
Epoch 22, global_step 57600, average loss: 0.25413647976318315
Epoch 22, global_step 57700, average loss: 0.21606998750146886
Epoch 22, global_step 57800, average loss: 0.22333226478447613
Epoch 22, global_step 57900, average loss: 0.24288765524084738
Epoch 22, global_step 58000, average loss: 0.16388097612849378
Epoch 22, global_step 58100, average loss: 0.20409249431475474
Epoch 22, global_step 58200, average loss: 0.19579300844219688
Epoch 22, global_step 58300, average loss: 0.163024332035493
Epoch 22, global_step 58400, average loss: 0.24443280834766484
Epoch 22, global_step 58500, average loss: 0.2670282540930202
Epoch 22, global_step 58600, average loss: 0.3147553317880011
Epoch 22, global_step 58700, average loss: 0.23092668300221703
Epoch 22, global_step 58800, average loss: 0.18447193201616754
Epoch 23, global_step 58900, average loss: 0.1738961487373308
Epoch 23, global_step 59000, average loss: 0.23222002261441957
Epoch 23, global_step 59100, average loss: 0.19763705281195143
Epoch 23, global_step 59200, average loss: 0.24505919891897066
Epoch 23, global_step 59300, average loss: 0.2748580672062235
Epoch 23, global_step 59400, average loss: 0.17584928213225795
Epoch 23, global_step 59500, average loss: 0.19197474974684156
Epoch 23, global_step 59600, average loss: 0.21236298183212057
Epoch 23, global_step 59700, average loss: 0.1738795079647389
Epoch 23, global_step 59800, average loss: 0.1653275958177983
Epoch 23, global_step 59900, average loss: 0.18756832531369583
Epoch 23, global_step 60000, average loss: 0.26580229446979503
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8594
Best model (step 60000, average valid loss 0.3468076387862126, average valid acc 0.859375) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.3468076387862126  -  Best loss 0.3468076387862126 at step 60000
Epoch 23, global_step 60100, average loss: 0.19026975219792802
Epoch 23, global_step 60200, average loss: 0.2698205358995256
Epoch 23, global_step 60300, average loss: 0.1552903516468723
Epoch 23, global_step 60400, average loss: 0.20848377378977603
Epoch 23, global_step 60500, average loss: 0.16771671193928342
Epoch 23, global_step 60600, average loss: 0.2721282916842756
Epoch 23, global_step 60700, average loss: 0.24990210160834977
Epoch 23, global_step 60800, average loss: 0.1804201907906463
Epoch 23, global_step 60900, average loss: 0.18092668737423082
Epoch 23, global_step 61000, average loss: 0.23037859856449358
Epoch 23, global_step 61100, average loss: 0.20488233934192976
Epoch 23, global_step 61200, average loss: 0.1928811187194151
Epoch 23, global_step 61300, average loss: 0.22186263639283424
Epoch 23, global_step 61400, average loss: 0.21911887343521813
Epoch 24, global_step 61500, average loss: 0.12137207556370413
Epoch 24, global_step 61600, average loss: 0.14616114009011652
Epoch 24, global_step 61700, average loss: 0.1399047813209836
Epoch 24, global_step 61800, average loss: 0.10101985835171945
Epoch 24, global_step 61900, average loss: 0.24285641672235214
Epoch 24, global_step 62000, average loss: 0.22580654802433855
Epoch 24, global_step 62100, average loss: 0.2149593604726033
Epoch 24, global_step 62200, average loss: 0.2220549207676595
Epoch 24, global_step 62300, average loss: 0.19083945499336552
Epoch 24, global_step 62400, average loss: 0.21217193291846342
Epoch 24, global_step 62500, average loss: 0.23868414950629813
Epoch 24, global_step 62600, average loss: 0.24389757548131455
Epoch 24, global_step 62700, average loss: 0.1741602317973593
Epoch 24, global_step 62800, average loss: 0.2007988650057814
Epoch 24, global_step 62900, average loss: 0.2549830753224887
Epoch 24, global_step 63000, average loss: 0.1944614509621897
Epoch 24, global_step 63100, average loss: 0.17277114000240545
Epoch 24, global_step 63200, average loss: 0.19619922964113357
Epoch 24, global_step 63300, average loss: 0.1842153339620927
Epoch 24, global_step 63400, average loss: 0.21330409019585203
Epoch 24, global_step 63500, average loss: 0.16496973324014108
Epoch 24, global_step 63600, average loss: 0.2388022065349651
Epoch 24, global_step 63700, average loss: 0.19881532823394082
Epoch 24, global_step 63800, average loss: 0.21371367368999927
Epoch 24, global_step 63900, average loss: 0.2235771111984286
Epoch 24, global_step 64000, average loss: 0.20231435025663813
Epoch 25, global_step 64100, average loss: 0.16986069484584732
Epoch 25, global_step 64200, average loss: 0.17310003438866262
Epoch 25, global_step 64300, average loss: 0.2092816160844086
Epoch 25, global_step 64400, average loss: 0.19962009787421267
Epoch 25, global_step 64500, average loss: 0.13563315652099844
Epoch 25, global_step 64600, average loss: 0.16193728681155334
Epoch 25, global_step 64700, average loss: 0.15903626223611356
Epoch 25, global_step 64800, average loss: 0.17945330197275325
Epoch 25, global_step 64900, average loss: 0.1745273073917997
Epoch 25, global_step 65000, average loss: 0.17610484963479395
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8521
Valid loss 0.3603548218984315  -  Best loss 0.3468076387862126 at step 60000
Epoch 25, global_step 65100, average loss: 0.26441960266489334
Epoch 25, global_step 65200, average loss: 0.21996949709322508
Epoch 25, global_step 65300, average loss: 0.23458769769444188
Epoch 25, global_step 65400, average loss: 0.1709208536569713
Epoch 25, global_step 65500, average loss: 0.15948588898405433
Epoch 25, global_step 65600, average loss: 0.20189072321889398
Epoch 25, global_step 65700, average loss: 0.1763479623641615
Epoch 25, global_step 65800, average loss: 0.20779116970581527
Epoch 25, global_step 65900, average loss: 0.2122991539262148
Epoch 25, global_step 66000, average loss: 0.1586984839051729
Epoch 25, global_step 66100, average loss: 0.18243582452338158
Epoch 25, global_step 66200, average loss: 0.2516213738262013
Epoch 25, global_step 66300, average loss: 0.16626975838142244
Epoch 25, global_step 66400, average loss: 0.18673671126623959
Epoch 25, global_step 66500, average loss: 0.21059314000955054
Epoch 26, global_step 66600, average loss: 0.17213977707502637
Epoch 26, global_step 66700, average loss: 0.20863572005386233
Epoch 26, global_step 66800, average loss: 0.15414609214101802
Epoch 26, global_step 66900, average loss: 0.16850560213675636
Epoch 26, global_step 67000, average loss: 0.1656622463329404
Epoch 26, global_step 67100, average loss: 0.18368501655648287
Epoch 26, global_step 67200, average loss: 0.17947093694761862
Epoch 26, global_step 67300, average loss: 0.2117823658927955
Epoch 26, global_step 67400, average loss: 0.1659227604544867
Epoch 26, global_step 67500, average loss: 0.1756201109401809
Epoch 26, global_step 67600, average loss: 0.22077658173471718
Epoch 26, global_step 67700, average loss: 0.17077732870777254
Epoch 26, global_step 67800, average loss: 0.16728673327605065
Epoch 26, global_step 67900, average loss: 0.15574197039626597
Epoch 26, global_step 68000, average loss: 0.18904226586408185
Epoch 26, global_step 68100, average loss: 0.19280238546838518
Epoch 26, global_step 68200, average loss: 0.230977084467886
Epoch 26, global_step 68300, average loss: 0.18226960458039684
Epoch 26, global_step 68400, average loss: 0.19691317009659542
Epoch 26, global_step 68500, average loss: 0.19586630802332367
Epoch 26, global_step 68600, average loss: 0.1877604928385699
Epoch 26, global_step 68700, average loss: 0.22821237777447095
Epoch 26, global_step 68800, average loss: 0.19138912773145422
Epoch 26, global_step 68900, average loss: 0.17111802231040202
Epoch 26, global_step 69000, average loss: 0.189287435392107
Epoch 26, global_step 69100, average loss: 0.2042111961239425
Epoch 27, global_step 69200, average loss: 0.1361571066587567
Epoch 27, global_step 69300, average loss: 0.17207393297456292
Epoch 27, global_step 69400, average loss: 0.20796413251868218
Epoch 27, global_step 69500, average loss: 0.173303310863339
Epoch 27, global_step 69600, average loss: 0.15412066290817164
Epoch 27, global_step 69700, average loss: 0.2023507539518323
Epoch 27, global_step 69800, average loss: 0.27290410144232735
Epoch 27, global_step 69900, average loss: 0.18284225811818033
Epoch 27, global_step 70000, average loss: 0.22865398983478372
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8380
Valid loss 0.38357920513579175  -  Best loss 0.3468076387862126 at step 60000
Epoch 27, global_step 70100, average loss: 0.19857889365241135
Epoch 27, global_step 70200, average loss: 0.24131877754876768
Epoch 27, global_step 70300, average loss: 0.1644183595630966
Epoch 27, global_step 70400, average loss: 0.2109660126473318
Epoch 27, global_step 70500, average loss: 0.15755574663820882
Epoch 27, global_step 70600, average loss: 0.2050396651317351
Epoch 27, global_step 70700, average loss: 0.20154882190523493
Epoch 27, global_step 70800, average loss: 0.19164379753350658
Epoch 27, global_step 70900, average loss: 0.18928492347207793
Epoch 27, global_step 71000, average loss: 0.23190850757800946
Epoch 27, global_step 71100, average loss: 0.1530244055140429
Epoch 27, global_step 71200, average loss: 0.17056008800176642
Epoch 27, global_step 71300, average loss: 0.14408349326582537
Epoch 27, global_step 71400, average loss: 0.18501027813770635
Epoch 27, global_step 71500, average loss: 0.14627540865621996
Epoch 27, global_step 71600, average loss: 0.20466759736373205
Epoch 28, global_step 71700, average loss: 0.2108877098269295
Epoch 28, global_step 71800, average loss: 0.17050921916474182
Epoch 28, global_step 71900, average loss: 0.22579370962728718
Epoch 28, global_step 72000, average loss: 0.17683819839287027
Epoch 28, global_step 72100, average loss: 0.16006487591323093
Epoch 28, global_step 72200, average loss: 0.16138635371364216
Epoch 28, global_step 72300, average loss: 0.19975077446644718
Epoch 28, global_step 72400, average loss: 0.17819045883363288
Epoch 28, global_step 72500, average loss: 0.11645867777035164
Epoch 28, global_step 72600, average loss: 0.23855469522772182
Epoch 28, global_step 72700, average loss: 0.16398989294473723
Epoch 28, global_step 72800, average loss: 0.13468208703721757
Epoch 28, global_step 72900, average loss: 0.1503548148124537
Epoch 28, global_step 73000, average loss: 0.18788293538564177
Epoch 28, global_step 73100, average loss: 0.1407430672913324
Epoch 28, global_step 73200, average loss: 0.21254008606643765
Epoch 28, global_step 73300, average loss: 0.21556179973289546
Epoch 28, global_step 73400, average loss: 0.1501615708022655
Epoch 28, global_step 73500, average loss: 0.20345588106989454
Epoch 28, global_step 73600, average loss: 0.22823915916687837
Epoch 28, global_step 73700, average loss: 0.16996177578585048
Epoch 28, global_step 73800, average loss: 0.12607787337088666
Epoch 28, global_step 73900, average loss: 0.18567040235073365
Epoch 28, global_step 74000, average loss: 0.14082052057994587
Epoch 28, global_step 74100, average loss: 0.2462496181055758
Epoch 28, global_step 74200, average loss: 0.13587431812738943
Epoch 29, global_step 74300, average loss: 0.1765898110951821
Epoch 29, global_step 74400, average loss: 0.17529271440565936
Epoch 29, global_step 74500, average loss: 0.15277715873289707
Epoch 29, global_step 74600, average loss: 0.13673993206815793
Epoch 29, global_step 74700, average loss: 0.15408104404818004
Epoch 29, global_step 74800, average loss: 0.15730049451984088
Epoch 29, global_step 74900, average loss: 0.15972903852682066
Epoch 29, global_step 75000, average loss: 0.20363336647795222
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8781
Best model (step 75000, average valid loss 0.30550542239773204, average valid acc 0.878125) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.30550542239773204  -  Best loss 0.30550542239773204 at step 75000
Epoch 29, global_step 75100, average loss: 0.12948138333493261
Epoch 29, global_step 75200, average loss: 0.12502770250670436
Epoch 29, global_step 75300, average loss: 0.21960089558295295
Epoch 29, global_step 75400, average loss: 0.143544852844243
Epoch 29, global_step 75500, average loss: 0.15296862658364263
Epoch 29, global_step 75600, average loss: 0.1948740575599004
Epoch 29, global_step 75700, average loss: 0.1630864818903501
Epoch 29, global_step 75800, average loss: 0.2823397184186615
Epoch 29, global_step 75900, average loss: 0.19964527685304348
Epoch 29, global_step 76000, average loss: 0.17516243285685051
Epoch 29, global_step 76100, average loss: 0.15330692723604444
Epoch 29, global_step 76200, average loss: 0.15225050423981884
Epoch 29, global_step 76300, average loss: 0.18777321324218066
Epoch 29, global_step 76400, average loss: 0.21369180492016313
Epoch 29, global_step 76500, average loss: 0.19950367210258263
Epoch 29, global_step 76600, average loss: 0.08903017851131154
Epoch 29, global_step 76700, average loss: 0.23325061066661873
Epoch 29, global_step 76800, average loss: 0.14612578558087988
Epoch 30, global_step 76900, average loss: 0.1558684776418886
Epoch 30, global_step 77000, average loss: 0.15968318967701634
Epoch 30, global_step 77100, average loss: 0.1389245632038728
Epoch 30, global_step 77200, average loss: 0.12281849107308516
Epoch 30, global_step 77300, average loss: 0.19952318567240582
Epoch 30, global_step 77400, average loss: 0.25776503607012274
Epoch 30, global_step 77500, average loss: 0.11697788521545589
Epoch 30, global_step 77600, average loss: 0.16551929506120358
Epoch 30, global_step 77700, average loss: 0.1693549318663645
Epoch 30, global_step 77800, average loss: 0.20988898185521976
Epoch 30, global_step 77900, average loss: 0.14006079664799473
Epoch 30, global_step 78000, average loss: 0.17919740624925906
Epoch 30, global_step 78100, average loss: 0.1481184896659397
Epoch 30, global_step 78200, average loss: 0.17912640706865204
Epoch 30, global_step 78300, average loss: 0.1807492511500459
Epoch 30, global_step 78400, average loss: 0.13723589843673836
Epoch 30, global_step 78500, average loss: 0.20808009024778584
Epoch 30, global_step 78600, average loss: 0.16565521715412615
Epoch 30, global_step 78700, average loss: 0.14036815874111197
Epoch 30, global_step 78800, average loss: 0.13916435360446486
Epoch 30, global_step 78900, average loss: 0.16365205433754454
Epoch 30, global_step 79000, average loss: 0.15741930213851446
Epoch 30, global_step 79100, average loss: 0.1620765224722345
Epoch 30, global_step 79200, average loss: 0.15309026250335592
Epoch 30, global_step 79300, average loss: 0.17609033344808267
Epoch 31, global_step 79400, average loss: 0.12746801777535438
Epoch 31, global_step 79500, average loss: 0.14362931743577065
Epoch 31, global_step 79600, average loss: 0.16828340180571102
Epoch 31, global_step 79700, average loss: 0.09953371729527134
Epoch 31, global_step 79800, average loss: 0.12127207931775047
Epoch 31, global_step 79900, average loss: 0.17815781401161077
Epoch 31, global_step 80000, average loss: 0.14854858991126094
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8802
Best model (step 80000, average valid loss 0.3442228312795768, average valid acc 0.8802083333333334) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.3442228312795768  -  Best loss 0.3442228312795768 at step 80000
Epoch 31, global_step 80100, average loss: 0.12447314996410569
Epoch 31, global_step 80200, average loss: 0.11259173250353342
Epoch 31, global_step 80300, average loss: 0.08126363882034639
Epoch 31, global_step 80400, average loss: 0.14858642689872795
Epoch 31, global_step 80500, average loss: 0.14123988249404648
Epoch 31, global_step 80600, average loss: 0.13973703075083904
Epoch 31, global_step 80700, average loss: 0.13691354958631563
Epoch 31, global_step 80800, average loss: 0.17018708330891968
Epoch 31, global_step 80900, average loss: 0.22353359159696992
Epoch 31, global_step 81000, average loss: 0.1764656258463583
Epoch 31, global_step 81100, average loss: 0.15202174608690255
Epoch 31, global_step 81200, average loss: 0.22124097060095665
Epoch 31, global_step 81300, average loss: 0.1368835331113951
Epoch 31, global_step 81400, average loss: 0.20069273526311007
Epoch 31, global_step 81500, average loss: 0.17014512773559545
Epoch 31, global_step 81600, average loss: 0.20412008563671408
Epoch 31, global_step 81700, average loss: 0.15110833267837734
Epoch 31, global_step 81800, average loss: 0.12668721654561524
Epoch 31, global_step 81900, average loss: 0.18667764212808835
Epoch 32, global_step 82000, average loss: 0.17551196031206928
Epoch 32, global_step 82100, average loss: 0.09887148176763731
Epoch 32, global_step 82200, average loss: 0.14847820732597028
Epoch 32, global_step 82300, average loss: 0.1276545315428666
Epoch 32, global_step 82400, average loss: 0.18880805561657327
Epoch 32, global_step 82500, average loss: 0.1430268545810395
Epoch 32, global_step 82600, average loss: 0.09244161795664695
Epoch 32, global_step 82700, average loss: 0.1576833701119176
Epoch 32, global_step 82800, average loss: 0.13332540040639287
Epoch 32, global_step 82900, average loss: 0.1760957931395751
Epoch 32, global_step 83000, average loss: 0.09546955457568401
Epoch 32, global_step 83100, average loss: 0.16743238807037414
Epoch 32, global_step 83200, average loss: 0.15930072845603718
Epoch 32, global_step 83300, average loss: 0.19216647854711483
Epoch 32, global_step 83400, average loss: 0.21336579513332254
Epoch 32, global_step 83500, average loss: 0.15545687561821978
Epoch 32, global_step 83600, average loss: 0.2460559120688049
Epoch 32, global_step 83700, average loss: 0.18812356153062865
Epoch 32, global_step 83800, average loss: 0.15888980963449284
Epoch 32, global_step 83900, average loss: 0.15016937263222643
Epoch 32, global_step 84000, average loss: 0.17239256679142273
Epoch 32, global_step 84100, average loss: 0.2084179776009114
Epoch 32, global_step 84200, average loss: 0.13891838097602885
Epoch 32, global_step 84300, average loss: 0.22030279732029157
Epoch 32, global_step 84400, average loss: 0.11275583028942492
Epoch 33, global_step 84500, average loss: 0.17586014136064476
Epoch 33, global_step 84600, average loss: 0.16080498161900322
Epoch 33, global_step 84700, average loss: 0.12344951748917082
Epoch 33, global_step 84800, average loss: 0.13140711534957517
Epoch 33, global_step 84900, average loss: 0.10167785442867171
Epoch 33, global_step 85000, average loss: 0.14288524066418176
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8880
Best model (step 85000, average valid loss 0.3979529353284661, average valid acc 0.8880208333333334) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.3979529353284661  -  Best loss 0.3979529353284661 at step 85000
Epoch 33, global_step 85100, average loss: 0.19968308603056356
Epoch 33, global_step 85200, average loss: 0.25868169603585556
Epoch 33, global_step 85300, average loss: 0.201511742749135
Epoch 33, global_step 85400, average loss: 0.1554359179655512
Epoch 33, global_step 85500, average loss: 0.12332855408989417
Epoch 33, global_step 85600, average loss: 0.13983060663416835
Epoch 33, global_step 85700, average loss: 0.1087154745625594
Epoch 33, global_step 85800, average loss: 0.09308307107032306
Epoch 33, global_step 85900, average loss: 0.18116401091599982
Epoch 33, global_step 86000, average loss: 0.1758146097023564
Epoch 33, global_step 86100, average loss: 0.15795800325937306
Epoch 33, global_step 86200, average loss: 0.14156945815837388
Epoch 33, global_step 86300, average loss: 0.09927686095579702
Epoch 33, global_step 86400, average loss: 0.11838186982728076
Epoch 33, global_step 86500, average loss: 0.1915080285699878
Epoch 33, global_step 86600, average loss: 0.14003277001727837
Epoch 33, global_step 86700, average loss: 0.11231042838538997
Epoch 33, global_step 86800, average loss: 0.14415966546137496
Epoch 33, global_step 86900, average loss: 0.24962116920552943
Epoch 33, global_step 87000, average loss: 0.14098167748485138
Epoch 34, global_step 87100, average loss: 0.14033121294520243
Epoch 34, global_step 87200, average loss: 0.1288217956394874
Epoch 34, global_step 87300, average loss: 0.09967654621825205
Epoch 34, global_step 87400, average loss: 0.1079213101042842
Epoch 34, global_step 87500, average loss: 0.11383710264191904
Epoch 34, global_step 87600, average loss: 0.13763962526303658
Epoch 34, global_step 87700, average loss: 0.1100428999397991
Epoch 34, global_step 87800, average loss: 0.1252808950680992
Epoch 34, global_step 87900, average loss: 0.0967287197886617
Epoch 34, global_step 88000, average loss: 0.17164777891444827
Epoch 34, global_step 88100, average loss: 0.19071504608524265
Epoch 34, global_step 88200, average loss: 0.17683857371423073
Epoch 34, global_step 88300, average loss: 0.1429914968304729
Epoch 34, global_step 88400, average loss: 0.15286677048195998
Epoch 34, global_step 88500, average loss: 0.10682884826332156
Epoch 34, global_step 88600, average loss: 0.14122517660955056
Epoch 34, global_step 88700, average loss: 0.11810334998990583
Epoch 34, global_step 88800, average loss: 0.15533402347653463
Epoch 34, global_step 88900, average loss: 0.11070048815527116
Epoch 34, global_step 89000, average loss: 0.1294269425240782
Epoch 34, global_step 89100, average loss: 0.178548556143287
Epoch 34, global_step 89200, average loss: 0.23276479365795238
Epoch 34, global_step 89300, average loss: 0.14519912179781386
Epoch 34, global_step 89400, average loss: 0.13632074718181683
Epoch 34, global_step 89500, average loss: 0.10206177956944884
Epoch 34, global_step 89600, average loss: 0.19573506125670975
Epoch 35, global_step 89700, average loss: 0.06725098207945848
Epoch 35, global_step 89800, average loss: 0.13110419239175827
Epoch 35, global_step 89900, average loss: 0.14407891905426368
Epoch 35, global_step 90000, average loss: 0.1626932161507648
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8854
Valid loss 0.34921322338924865  -  Best loss 0.3979529353284661 at step 85000
Epoch 35, global_step 90100, average loss: 0.11280027833963686
Epoch 35, global_step 90200, average loss: 0.08992724274739886
Epoch 35, global_step 90300, average loss: 0.09262675033733103
Epoch 35, global_step 90400, average loss: 0.13789749133607984
Epoch 35, global_step 90500, average loss: 0.15572660207682928
Epoch 35, global_step 90600, average loss: 0.23058741824213938
Epoch 35, global_step 90700, average loss: 0.21407896564032852
Epoch 35, global_step 90800, average loss: 0.14095909725478123
Epoch 35, global_step 90900, average loss: 0.1756261961605196
Epoch 35, global_step 91000, average loss: 0.112551072202441
Epoch 35, global_step 91100, average loss: 0.17517752655527147
Epoch 35, global_step 91200, average loss: 0.18116407203215204
Epoch 35, global_step 91300, average loss: 0.17429616852914478
Epoch 35, global_step 91400, average loss: 0.19311433916693205
Epoch 35, global_step 91500, average loss: 0.13665524875319535
Epoch 35, global_step 91600, average loss: 0.17635721007689426
Epoch 35, global_step 91700, average loss: 0.09217704105209122
Epoch 35, global_step 91800, average loss: 0.1900824416231262
Epoch 35, global_step 91900, average loss: 0.1852114949508541
Epoch 35, global_step 92000, average loss: 0.07759969596303563
Epoch 35, global_step 92100, average loss: 0.1313038386289918
Epoch 36, global_step 92200, average loss: 0.14831783149995317
Epoch 36, global_step 92300, average loss: 0.12038769781887822
Epoch 36, global_step 92400, average loss: 0.22689424412943482
Epoch 36, global_step 92500, average loss: 0.14894160355321218
Epoch 36, global_step 92600, average loss: 0.08722878409502301
Epoch 36, global_step 92700, average loss: 0.1458449810903767
Epoch 36, global_step 92800, average loss: 0.1694924103665471
Epoch 36, global_step 92900, average loss: 0.11007247586210724
Epoch 36, global_step 93000, average loss: 0.08233193440195465
Epoch 36, global_step 93100, average loss: 0.17668456355153467
Epoch 36, global_step 93200, average loss: 0.14138976045120216
Epoch 36, global_step 93300, average loss: 0.141752004673981
Epoch 36, global_step 93400, average loss: 0.13944054025763764
Epoch 36, global_step 93500, average loss: 0.1997837176801113
Epoch 36, global_step 93600, average loss: 0.15927530974240653
Epoch 36, global_step 93700, average loss: 0.18168388470410718
Epoch 36, global_step 93800, average loss: 0.16373027528094097
Epoch 36, global_step 93900, average loss: 0.08253497864072415
Epoch 36, global_step 94000, average loss: 0.15573096884159895
Epoch 36, global_step 94100, average loss: 0.1478316098346477
Epoch 36, global_step 94200, average loss: 0.11970947211259045
Epoch 36, global_step 94300, average loss: 0.14718543418443006
Epoch 36, global_step 94400, average loss: 0.13392084236584195
Epoch 36, global_step 94500, average loss: 0.19676818756590364
Epoch 36, global_step 94600, average loss: 0.19415224827193014
Epoch 36, global_step 94700, average loss: 0.11428843669855268
Epoch 37, global_step 94800, average loss: 0.1053956104667668
Epoch 37, global_step 94900, average loss: 0.07236168392875697
Epoch 37, global_step 95000, average loss: 0.12955240423601935
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8885
Best model (step 95000, average valid loss 0.3439082458284741, average valid acc 0.8885416666666667) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.3439082458284741  -  Best loss 0.3439082458284741 at step 95000
Epoch 37, global_step 95100, average loss: 0.13250216578300753
Epoch 37, global_step 95200, average loss: 0.07614230827701249
Epoch 37, global_step 95300, average loss: 0.07059824622789165
Epoch 37, global_step 95400, average loss: 0.04463059659239661
Epoch 37, global_step 95500, average loss: 0.08813106887941104
Epoch 37, global_step 95600, average loss: 0.07162784092732181
Epoch 37, global_step 95700, average loss: 0.13341217143752146
Epoch 37, global_step 95800, average loss: 0.15061136821623222
Epoch 37, global_step 95900, average loss: 0.08811682635001489
Epoch 37, global_step 96000, average loss: 0.1431162611890977
Epoch 37, global_step 96100, average loss: 0.1358714663457431
Epoch 37, global_step 96200, average loss: 0.13390327412347688
Epoch 37, global_step 96300, average loss: 0.12046573564090067
Epoch 37, global_step 96400, average loss: 0.1787270292960966
Epoch 37, global_step 96500, average loss: 0.1590349174869334
Epoch 37, global_step 96600, average loss: 0.16563064670779568
Epoch 37, global_step 96700, average loss: 0.1624567489641413
Epoch 37, global_step 96800, average loss: 0.164609317290342
Epoch 37, global_step 96900, average loss: 0.13645846930165134
Epoch 37, global_step 97000, average loss: 0.135201199033545
Epoch 37, global_step 97100, average loss: 0.12103754959967773
Epoch 37, global_step 97200, average loss: 0.23867719000034412
Epoch 38, global_step 97300, average loss: 0.19012017515120533
Epoch 38, global_step 97400, average loss: 0.1135107998474632
Epoch 38, global_step 97500, average loss: 0.07791739748823602
Epoch 38, global_step 97600, average loss: 0.09645484151133132
Epoch 38, global_step 97700, average loss: 0.13413046152742025
Epoch 38, global_step 97800, average loss: 0.08685645373683655
Epoch 38, global_step 97900, average loss: 0.08877419226242637
Epoch 38, global_step 98000, average loss: 0.13235016628044832
Epoch 38, global_step 98100, average loss: 0.12483115537070262
Epoch 38, global_step 98200, average loss: 0.15691952293662326
Epoch 38, global_step 98300, average loss: 0.12684726639963628
Epoch 38, global_step 98400, average loss: 0.1158996975649643
Epoch 38, global_step 98500, average loss: 0.11819150615949184
Epoch 38, global_step 98600, average loss: 0.21456641619352013
Epoch 38, global_step 98700, average loss: 0.13272986290809058
Epoch 38, global_step 98800, average loss: 0.14415035623427686
Epoch 38, global_step 98900, average loss: 0.13170103564141755
Epoch 38, global_step 99000, average loss: 0.1687967754159763
Epoch 38, global_step 99100, average loss: 0.08400046953443961
Epoch 38, global_step 99200, average loss: 0.12928530159362708
Epoch 38, global_step 99300, average loss: 0.15293143564886122
Epoch 38, global_step 99400, average loss: 0.16750068794008258
Epoch 38, global_step 99500, average loss: 0.1103412177401333
Epoch 38, global_step 99600, average loss: 0.1845423521651901
Epoch 38, global_step 99700, average loss: 0.14115877549029393
Epoch 38, global_step 99800, average loss: 0.13440496005947353
Epoch 39, global_step 99900, average loss: 0.0989856250412413
Epoch 39, global_step 100000, average loss: 0.07516041359122028
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8781
Valid loss 0.38449075938087934  -  Best loss 0.3439082458284741 at step 95000
Epoch 39, global_step 100100, average loss: 0.10594858397766074
Epoch 39, global_step 100200, average loss: 0.19695077675878564
Epoch 39, global_step 100300, average loss: 0.13372117543782225
Epoch 39, global_step 100400, average loss: 0.12834669233296153
Epoch 39, global_step 100500, average loss: 0.13498987439845223
Epoch 39, global_step 100600, average loss: 0.1241438569148886
Epoch 39, global_step 100700, average loss: 0.09994397879694589
Epoch 39, global_step 100800, average loss: 0.14699592124648916
Epoch 39, global_step 100900, average loss: 0.12051780534722639
Epoch 39, global_step 101000, average loss: 0.1190943710963984
Epoch 39, global_step 101100, average loss: 0.12871097436094714
Epoch 39, global_step 101200, average loss: 0.14792683543048044
Epoch 39, global_step 101300, average loss: 0.07243592236460245
Epoch 39, global_step 101400, average loss: 0.17087740069913707
Epoch 39, global_step 101500, average loss: 0.10396731818920671
Epoch 39, global_step 101600, average loss: 0.14245024062336598
Epoch 39, global_step 101700, average loss: 0.15007369491515418
Epoch 39, global_step 101800, average loss: 0.0605301663631326
Epoch 39, global_step 101900, average loss: 0.10128738368024642
Epoch 39, global_step 102000, average loss: 0.1051050180365928
Epoch 39, global_step 102100, average loss: 0.1960269583903937
Epoch 39, global_step 102200, average loss: 0.17122885220833267
Epoch 39, global_step 102300, average loss: 0.1637998660827361
Epoch 39, global_step 102400, average loss: 0.14639487091189948
Epoch 40, global_step 102500, average loss: 0.16206555384604143
Epoch 40, global_step 102600, average loss: 0.10887848256668803
Epoch 40, global_step 102700, average loss: 0.1119255229295959
Epoch 40, global_step 102800, average loss: 0.07448585921632912
Epoch 40, global_step 102900, average loss: 0.10049586491419177
Epoch 40, global_step 103000, average loss: 0.12211149561706407
Epoch 40, global_step 103100, average loss: 0.12199681037272966
Epoch 40, global_step 103200, average loss: 0.10016717272654205
Epoch 40, global_step 103300, average loss: 0.1267200987160686
Epoch 40, global_step 103400, average loss: 0.142936389576098
Epoch 40, global_step 103500, average loss: 0.16233069386249555
Epoch 40, global_step 103600, average loss: 0.16465615263110522
Epoch 40, global_step 103700, average loss: 0.18329054696423555
Epoch 40, global_step 103800, average loss: 0.11400756627474039
Epoch 40, global_step 103900, average loss: 0.11998753979838511
Epoch 40, global_step 104000, average loss: 0.09980593947464513
Epoch 40, global_step 104100, average loss: 0.09411275611026212
Epoch 40, global_step 104200, average loss: 0.1024435174708924
Epoch 40, global_step 104300, average loss: 0.12238801322102517
Epoch 40, global_step 104400, average loss: 0.11872728068010474
Epoch 40, global_step 104500, average loss: 0.11190859329370141
Epoch 40, global_step 104600, average loss: 0.13371344706742094
Epoch 40, global_step 104700, average loss: 0.14216821895795875
Epoch 40, global_step 104800, average loss: 0.10351453200601099
Epoch 40, global_step 104900, average loss: 0.14064195040133198
save checkpoint at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint/epoch40
Epoch 41, global_step 105000, average loss: 0.12140899047975835
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8870
Valid loss 0.3631250032311078  -  Best loss 0.3439082458284741 at step 95000
Epoch 41, global_step 105100, average loss: 0.08274470136679156
Epoch 41, global_step 105200, average loss: 0.10667360379138699
Epoch 41, global_step 105300, average loss: 0.10112855369567114
Epoch 41, global_step 105400, average loss: 0.0668238682876472
Epoch 41, global_step 105500, average loss: 0.12478981512787868
Epoch 41, global_step 105600, average loss: 0.12639652073052277
Epoch 41, global_step 105700, average loss: 0.19300408766470356
Epoch 41, global_step 105800, average loss: 0.12073335203967872
Epoch 41, global_step 105900, average loss: 0.0776030506382449
Epoch 41, global_step 106000, average loss: 0.09696747023026546
Epoch 41, global_step 106100, average loss: 0.1549220297389911
Epoch 41, global_step 106200, average loss: 0.15058723966001708
Epoch 41, global_step 106300, average loss: 0.10063773151992791
Epoch 41, global_step 106400, average loss: 0.14982061493403306
Epoch 41, global_step 106500, average loss: 0.12885312060770956
Epoch 41, global_step 106600, average loss: 0.11731259359603427
Epoch 41, global_step 106700, average loss: 0.13147140316046715
Epoch 41, global_step 106800, average loss: 0.17295222302156618
Epoch 41, global_step 106900, average loss: 0.10025806335386733
Epoch 41, global_step 107000, average loss: 0.11467862815672561
Epoch 41, global_step 107100, average loss: 0.1365487956582365
Epoch 41, global_step 107200, average loss: 0.11968721542940329
Epoch 41, global_step 107300, average loss: 0.11586310032089386
Epoch 41, global_step 107400, average loss: 0.10055038249960489
Epoch 41, global_step 107500, average loss: 0.09446161365751322
Epoch 42, global_step 107600, average loss: 0.06914601296346518
Epoch 42, global_step 107700, average loss: 0.09918447746033053
Epoch 42, global_step 107800, average loss: 0.1039845565784708
Epoch 42, global_step 107900, average loss: 0.07382431659396388
Epoch 42, global_step 108000, average loss: 0.10116549888396548
Epoch 42, global_step 108100, average loss: 0.11706796073875012
Epoch 42, global_step 108200, average loss: 0.10203237048815936
Epoch 42, global_step 108300, average loss: 0.12372923458686273
Epoch 42, global_step 108400, average loss: 0.12088264255908143
Epoch 42, global_step 108500, average loss: 0.11939189073000307
Epoch 42, global_step 108600, average loss: 0.11392241173682123
Epoch 42, global_step 108700, average loss: 0.1386276556982193
Epoch 42, global_step 108800, average loss: 0.14159568134993605
Epoch 42, global_step 108900, average loss: 0.1397814314183779
Epoch 42, global_step 109000, average loss: 0.13995009155973093
Epoch 42, global_step 109100, average loss: 0.10640729752230982
Epoch 42, global_step 109200, average loss: 0.1826902913691083
Epoch 42, global_step 109300, average loss: 0.11350583148290752
Epoch 42, global_step 109400, average loss: 0.18623293984743214
Epoch 42, global_step 109500, average loss: 0.10189203776037176
Epoch 42, global_step 109600, average loss: 0.12450387104814581
Epoch 42, global_step 109700, average loss: 0.13592821560614538
Epoch 42, global_step 109800, average loss: 0.1487447387949942
Epoch 42, global_step 109900, average loss: 0.14820929168137809
Epoch 42, global_step 110000, average loss: 0.12647821465212472
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8854
Valid loss 0.36243263596501457  -  Best loss 0.3439082458284741 at step 95000
Epoch 43, global_step 110100, average loss: 0.08661617007695895
Epoch 43, global_step 110200, average loss: 0.11003925480756152
Epoch 43, global_step 110300, average loss: 0.12714417121704172
Epoch 43, global_step 110400, average loss: 0.09576733558187697
Epoch 43, global_step 110500, average loss: 0.05705076839334652
Epoch 43, global_step 110600, average loss: 0.07256385263543053
Epoch 43, global_step 110700, average loss: 0.1388858555592742
Epoch 43, global_step 110800, average loss: 0.1139707798411473
Epoch 43, global_step 110900, average loss: 0.09724012084909191
Epoch 43, global_step 111000, average loss: 0.08416178359944752
Epoch 43, global_step 111100, average loss: 0.13031940599652445
Epoch 43, global_step 111200, average loss: 0.16247552724209527
Epoch 43, global_step 111300, average loss: 0.20744153418952918
Epoch 43, global_step 111400, average loss: 0.12352305350868846
Epoch 43, global_step 111500, average loss: 0.07809332169195841
Epoch 43, global_step 111600, average loss: 0.13217636519289955
Epoch 43, global_step 111700, average loss: 0.1633612284724586
Epoch 43, global_step 111800, average loss: 0.08244847203677637
Epoch 43, global_step 111900, average loss: 0.10701963025552687
Epoch 43, global_step 112000, average loss: 0.14133887070885975
Epoch 43, global_step 112100, average loss: 0.11395641816303397
Epoch 43, global_step 112200, average loss: 0.11983628102228977
Epoch 43, global_step 112300, average loss: 0.08340152230088278
Epoch 43, global_step 112400, average loss: 0.14455103572425287
Epoch 43, global_step 112500, average loss: 0.12898659230326304
Epoch 43, global_step 112600, average loss: 0.11152615035014606
Epoch 44, global_step 112700, average loss: 0.07427858929982904
Epoch 44, global_step 112800, average loss: 0.0812400781537508
Epoch 44, global_step 112900, average loss: 0.06422080372667552
Epoch 44, global_step 113000, average loss: 0.0899238781339227
Epoch 44, global_step 113100, average loss: 0.09393906126100773
Epoch 44, global_step 113200, average loss: 0.10611124516290146
Epoch 44, global_step 113300, average loss: 0.10297714383232233
Epoch 44, global_step 113400, average loss: 0.10039077453970094
Epoch 44, global_step 113500, average loss: 0.14543951323892543
Epoch 44, global_step 113600, average loss: 0.15483308177335858
Epoch 44, global_step 113700, average loss: 0.1241250727181614
Epoch 44, global_step 113800, average loss: 0.07105080364977766
Epoch 44, global_step 113900, average loss: 0.11514266969898017
Epoch 44, global_step 114000, average loss: 0.19346531378843793
Epoch 44, global_step 114100, average loss: 0.11113964861669956
Epoch 44, global_step 114200, average loss: 0.1355911798334637
Epoch 44, global_step 114300, average loss: 0.0684652329252276
Epoch 44, global_step 114400, average loss: 0.08968208272985066
Epoch 44, global_step 114500, average loss: 0.11444571266656567
Epoch 44, global_step 114600, average loss: 0.22944811704881432
Epoch 44, global_step 114700, average loss: 0.13152150445541338
Epoch 44, global_step 114800, average loss: 0.0815946430423719
Epoch 44, global_step 114900, average loss: 0.1283911773467844
Epoch 44, global_step 115000, average loss: 0.1029303665299085
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8833
Valid loss 0.38020750999022196  -  Best loss 0.3439082458284741 at step 95000
Epoch 44, global_step 115100, average loss: 0.11855319096313906
Epoch 44, global_step 115200, average loss: 0.11472992893330229
Epoch 45, global_step 115300, average loss: 0.11621605544609338
Epoch 45, global_step 115400, average loss: 0.10359181868003361
Epoch 45, global_step 115500, average loss: 0.13954565534244467
Epoch 45, global_step 115600, average loss: 0.16640155253317063
Epoch 45, global_step 115700, average loss: 0.08783045605650841
Epoch 45, global_step 115800, average loss: 0.14857992487748561
Epoch 45, global_step 115900, average loss: 0.14873158557871646
Epoch 45, global_step 116000, average loss: 0.10895379459736432
Epoch 45, global_step 116100, average loss: 0.11589233916805824
Epoch 45, global_step 116200, average loss: 0.10946862156582939
Epoch 45, global_step 116300, average loss: 0.10911483757736277
Epoch 45, global_step 116400, average loss: 0.1634558691750135
Epoch 45, global_step 116500, average loss: 0.1362509040601799
Epoch 45, global_step 116600, average loss: 0.14799501301404233
Epoch 45, global_step 116700, average loss: 0.12054724963720219
Epoch 45, global_step 116800, average loss: 0.05488201153380942
Epoch 45, global_step 116900, average loss: 0.0930061228163686
Epoch 45, global_step 117000, average loss: 0.11199252497925044
Epoch 45, global_step 117100, average loss: 0.1360873432905646
Epoch 45, global_step 117200, average loss: 0.0855228949474622
Epoch 45, global_step 117300, average loss: 0.12791123040045932
Epoch 45, global_step 117400, average loss: 0.142826275574007
Epoch 45, global_step 117500, average loss: 0.07640368712953205
Epoch 45, global_step 117600, average loss: 0.10394231372232753
Epoch 45, global_step 117700, average loss: 0.14374123369751032
Epoch 46, global_step 117800, average loss: 0.15231912964485672
Epoch 46, global_step 117900, average loss: 0.10011402078594983
Epoch 46, global_step 118000, average loss: 0.09166815272332314
Epoch 46, global_step 118100, average loss: 0.11601187991047482
Epoch 46, global_step 118200, average loss: 0.11067097072034812
Epoch 46, global_step 118300, average loss: 0.09792197467981169
Epoch 46, global_step 118400, average loss: 0.12231960561970481
Epoch 46, global_step 118500, average loss: 0.12464295552996191
Epoch 46, global_step 118600, average loss: 0.20399314141679498
Epoch 46, global_step 118700, average loss: 0.161043802725726
Epoch 46, global_step 118800, average loss: 0.10347468255073182
Epoch 46, global_step 118900, average loss: 0.14230415536068905
Epoch 46, global_step 119000, average loss: 0.14491842191309842
Epoch 46, global_step 119100, average loss: 0.13456197588766372
Epoch 46, global_step 119200, average loss: 0.12436347082792054
Epoch 46, global_step 119300, average loss: 0.0992613389019607
Epoch 46, global_step 119400, average loss: 0.10341135137055972
Epoch 46, global_step 119500, average loss: 0.11060380659208022
Epoch 46, global_step 119600, average loss: 0.09812120161550411
Epoch 46, global_step 119700, average loss: 0.057558723147085405
Epoch 46, global_step 119800, average loss: 0.11654458419707225
Epoch 46, global_step 119900, average loss: 0.0654326512564512
Epoch 46, global_step 120000, average loss: 0.14895737784761878
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8906
Best model (step 120000, average valid loss 0.44291573419898295, average valid acc 0.890625) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.44291573419898295  -  Best loss 0.44291573419898295 at step 120000
Epoch 46, global_step 120100, average loss: 0.08454983326941147
Epoch 46, global_step 120200, average loss: 0.10749140569474548
Epoch 46, global_step 120300, average loss: 0.1352729416848888
Epoch 47, global_step 120400, average loss: 0.1213705878212204
Epoch 47, global_step 120500, average loss: 0.09754977293756383
Epoch 47, global_step 120600, average loss: 0.12287831677938811
Epoch 47, global_step 120700, average loss: 0.12482503034909315
Epoch 47, global_step 120800, average loss: 0.08069009654311231
Epoch 47, global_step 120900, average loss: 0.11579403190426092
Epoch 47, global_step 121000, average loss: 0.10920050460252241
Epoch 47, global_step 121100, average loss: 0.1339125426942337
Epoch 47, global_step 121200, average loss: 0.08750866973350639
Epoch 47, global_step 121300, average loss: 0.06787156824906561
Epoch 47, global_step 121400, average loss: 0.10280742263021239
Epoch 47, global_step 121500, average loss: 0.1509640477787252
Epoch 47, global_step 121600, average loss: 0.09209211648671044
Epoch 47, global_step 121700, average loss: 0.1636268736458078
Epoch 47, global_step 121800, average loss: 0.09976636344556028
Epoch 47, global_step 121900, average loss: 0.1584641915586326
Epoch 47, global_step 122000, average loss: 0.12489542587914912
Epoch 47, global_step 122100, average loss: 0.0865250239076704
Epoch 47, global_step 122200, average loss: 0.16831490139913513
Epoch 47, global_step 122300, average loss: 0.10383937614933529
Epoch 47, global_step 122400, average loss: 0.09255467780440085
Epoch 47, global_step 122500, average loss: 0.1253141208615125
Epoch 47, global_step 122600, average loss: 0.06308974321418645
Epoch 47, global_step 122700, average loss: 0.08305459145907662
Epoch 47, global_step 122800, average loss: 0.08607646213513362
Epoch 48, global_step 122900, average loss: 0.05535456635090668
Epoch 48, global_step 123000, average loss: 0.06324319665411167
Epoch 48, global_step 123100, average loss: 0.12764812604054895
Epoch 48, global_step 123200, average loss: 0.06255779103732494
Epoch 48, global_step 123300, average loss: 0.09288291033022687
Epoch 48, global_step 123400, average loss: 0.06680163715020171
Epoch 48, global_step 123500, average loss: 0.13122553535118642
Epoch 48, global_step 123600, average loss: 0.0699812018198645
Epoch 48, global_step 123700, average loss: 0.13512913287038827
Epoch 48, global_step 123800, average loss: 0.15119027900422224
Epoch 48, global_step 123900, average loss: 0.10287668453198422
Epoch 48, global_step 124000, average loss: 0.12084617456246632
Epoch 48, global_step 124100, average loss: 0.11228108479135698
Epoch 48, global_step 124200, average loss: 0.06949208053669281
Epoch 48, global_step 124300, average loss: 0.08869314199055225
Epoch 48, global_step 124400, average loss: 0.179828560549322
Epoch 48, global_step 124500, average loss: 0.11468815526040999
Epoch 48, global_step 124600, average loss: 0.11249851040640352
Epoch 48, global_step 124700, average loss: 0.03574322340220533
Epoch 48, global_step 124800, average loss: 0.09272335465917422
Epoch 48, global_step 124900, average loss: 0.07850518313556677
Epoch 48, global_step 125000, average loss: 0.09339537068990467
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8833
Valid loss 0.5078396718280935  -  Best loss 0.44291573419898295 at step 120000
Epoch 48, global_step 125100, average loss: 0.09610498088972236
Epoch 48, global_step 125200, average loss: 0.13476613012335292
Epoch 48, global_step 125300, average loss: 0.20566161241156805
Epoch 48, global_step 125400, average loss: 0.1379775198331481
Epoch 49, global_step 125500, average loss: 0.10095464516216453
Epoch 49, global_step 125600, average loss: 0.07769623751595646
Epoch 49, global_step 125700, average loss: 0.057795769629337884
Epoch 49, global_step 125800, average loss: 0.09392805211584346
Epoch 49, global_step 125900, average loss: 0.08999348581699451
Epoch 49, global_step 126000, average loss: 0.06815930858847423
Epoch 49, global_step 126100, average loss: 0.12122621953792986
Epoch 49, global_step 126200, average loss: 0.12271277731320879
Epoch 49, global_step 126300, average loss: 0.1490598094103916
Epoch 49, global_step 126400, average loss: 0.11304391156838392
Epoch 49, global_step 126500, average loss: 0.08811156188559835
Epoch 49, global_step 126600, average loss: 0.03893778821806336
Epoch 49, global_step 126700, average loss: 0.07810096028268163
Epoch 49, global_step 126800, average loss: 0.12004088896785106
Epoch 49, global_step 126900, average loss: 0.05661857700008113
Epoch 49, global_step 127000, average loss: 0.12146573537098447
Epoch 49, global_step 127100, average loss: 0.08370663399469777
Epoch 49, global_step 127200, average loss: 0.1201835781689806
Epoch 49, global_step 127300, average loss: 0.05899974115152872
Epoch 49, global_step 127400, average loss: 0.24512026655196678
Epoch 49, global_step 127500, average loss: 0.11041384228035894
Epoch 49, global_step 127600, average loss: 0.11990887899275549
Epoch 49, global_step 127700, average loss: 0.11261330759938573
Epoch 49, global_step 127800, average loss: 0.11873041465703864
Epoch 49, global_step 127900, average loss: 0.10158955363898713
Epoch 49, global_step 128000, average loss: 0.12859621505820543
Epoch 50, global_step 128100, average loss: 0.06728969630108622
Epoch 50, global_step 128200, average loss: 0.06509166530286166
Epoch 50, global_step 128300, average loss: 0.08448992629644636
Epoch 50, global_step 128400, average loss: 0.0916789163924841
Epoch 50, global_step 128500, average loss: 0.05363509231094213
Epoch 50, global_step 128600, average loss: 0.07960111462783971
Epoch 50, global_step 128700, average loss: 0.1001669107674752
Epoch 50, global_step 128800, average loss: 0.07878884451034537
Epoch 50, global_step 128900, average loss: 0.06536000457450428
Epoch 50, global_step 129000, average loss: 0.060173466979977094
Epoch 50, global_step 129100, average loss: 0.10969453677589627
Epoch 50, global_step 129200, average loss: 0.10534330596525251
Epoch 50, global_step 129300, average loss: 0.07498675014376203
Epoch 50, global_step 129400, average loss: 0.0831528334234099
Epoch 50, global_step 129500, average loss: 0.08177375730680068
Epoch 50, global_step 129600, average loss: 0.09540202676344052
Epoch 50, global_step 129700, average loss: 0.08852430877781443
Epoch 50, global_step 129800, average loss: 0.12002752583881375
Epoch 50, global_step 129900, average loss: 0.06970133440492646
Epoch 50, global_step 130000, average loss: 0.12604380510543706
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8979
Best model (step 130000, average valid loss 0.3913421481334113, average valid acc 0.8979166666666667) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.3913421481334113  -  Best loss 0.3913421481334113 at step 130000
Epoch 50, global_step 130100, average loss: 0.08956106105797516
Epoch 50, global_step 130200, average loss: 0.10148701682854153
Epoch 50, global_step 130300, average loss: 0.10721241234190529
Epoch 50, global_step 130400, average loss: 0.147787670589787
Epoch 50, global_step 130500, average loss: 0.14044671495204966
Epoch 51, global_step 130600, average loss: 0.1304851706689078
Epoch 51, global_step 130700, average loss: 0.07739954344535363
Epoch 51, global_step 130800, average loss: 0.08963473940180848
Epoch 51, global_step 130900, average loss: 0.14117030722834897
Epoch 51, global_step 131000, average loss: 0.09987455193990172
Epoch 51, global_step 131100, average loss: 0.12078224094093457
Epoch 51, global_step 131200, average loss: 0.1508165733441274
Epoch 51, global_step 131300, average loss: 0.10533882371069922
Epoch 51, global_step 131400, average loss: 0.10653172897997137
Epoch 51, global_step 131500, average loss: 0.1654622226324136
Epoch 51, global_step 131600, average loss: 0.06323460113828333
Epoch 51, global_step 131700, average loss: 0.07981188080109859
Epoch 51, global_step 131800, average loss: 0.1065637014515596
Epoch 51, global_step 131900, average loss: 0.15140181440285233
Epoch 51, global_step 132000, average loss: 0.08685317963776469
Epoch 51, global_step 132100, average loss: 0.12206908853011555
Epoch 51, global_step 132200, average loss: 0.10114981135408016
Epoch 51, global_step 132300, average loss: 0.07181067807701766
Epoch 51, global_step 132400, average loss: 0.07994317090193363
Epoch 51, global_step 132500, average loss: 0.028045775877762934
Epoch 51, global_step 132600, average loss: 0.07257994480558409
Epoch 51, global_step 132700, average loss: 0.06590852445846394
Epoch 51, global_step 132800, average loss: 0.1854332289361264
Epoch 51, global_step 132900, average loss: 0.14294557223667653
Epoch 51, global_step 133000, average loss: 0.058780644109174315
Epoch 51, global_step 133100, average loss: 0.09406735182688862
Epoch 52, global_step 133200, average loss: 0.0646549071350455
Epoch 52, global_step 133300, average loss: 0.05746473914332455
Epoch 52, global_step 133400, average loss: 0.08203118742621882
Epoch 52, global_step 133500, average loss: 0.19563740948742633
Epoch 52, global_step 133600, average loss: 0.07556638283640496
Epoch 52, global_step 133700, average loss: 0.10399286901545565
Epoch 52, global_step 133800, average loss: 0.11947724267000012
Epoch 52, global_step 133900, average loss: 0.13936431951340636
Epoch 52, global_step 134000, average loss: 0.11938257231850002
Epoch 52, global_step 134100, average loss: 0.12330090064544492
Epoch 52, global_step 134200, average loss: 0.10342046986046625
Epoch 52, global_step 134300, average loss: 0.08851969800565712
Epoch 52, global_step 134400, average loss: 0.07438759783970454
Epoch 52, global_step 134500, average loss: 0.09659278390383406
Epoch 52, global_step 134600, average loss: 0.0832406418917526
Epoch 52, global_step 134700, average loss: 0.07470751393062529
Epoch 52, global_step 134800, average loss: 0.06550546258382382
Epoch 52, global_step 134900, average loss: 0.09149118185850966
Epoch 52, global_step 135000, average loss: 0.07568325046275276
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8880
Valid loss 0.43324389739655017  -  Best loss 0.3913421481334113 at step 130000
Epoch 52, global_step 135100, average loss: 0.08514791353358304
Epoch 52, global_step 135200, average loss: 0.104746011399875
Epoch 52, global_step 135300, average loss: 0.11191810939908464
Epoch 52, global_step 135400, average loss: 0.047198850794993634
Epoch 52, global_step 135500, average loss: 0.14844251575752423
Epoch 52, global_step 135600, average loss: 0.17523162353678345
Epoch 53, global_step 135700, average loss: 0.07658924989202205
Epoch 53, global_step 135800, average loss: 0.07410908776160795
Epoch 53, global_step 135900, average loss: 0.125209766781918
Epoch 53, global_step 136000, average loss: 0.06454362449421751
Epoch 53, global_step 136100, average loss: 0.10341280771150195
Epoch 53, global_step 136200, average loss: 0.07953233901283965
Epoch 53, global_step 136300, average loss: 0.10606338515412063
Epoch 53, global_step 136400, average loss: 0.07840143034896756
Epoch 53, global_step 136500, average loss: 0.03648796475630661
Epoch 53, global_step 136600, average loss: 0.07053898204288998
Epoch 53, global_step 136700, average loss: 0.11976257708960475
Epoch 53, global_step 136800, average loss: 0.07332290818492765
Epoch 53, global_step 136900, average loss: 0.10138854035856638
Epoch 53, global_step 137000, average loss: 0.11253297680468677
Epoch 53, global_step 137100, average loss: 0.1109470534771026
Epoch 53, global_step 137200, average loss: 0.06018419629293931
Epoch 53, global_step 137300, average loss: 0.11456680631497874
Epoch 53, global_step 137400, average loss: 0.11298102981279953
Epoch 53, global_step 137500, average loss: 0.13666256804750446
Epoch 53, global_step 137600, average loss: 0.12508602099584096
Epoch 53, global_step 137700, average loss: 0.05662408805845189
Epoch 53, global_step 137800, average loss: 0.10934847855722182
Epoch 53, global_step 137900, average loss: 0.10861186805777834
Epoch 53, global_step 138000, average loss: 0.07795015832714852
Epoch 53, global_step 138100, average loss: 0.10819598264817615
Epoch 53, global_step 138200, average loss: 0.13084761925063504
Epoch 54, global_step 138300, average loss: 0.09151076567606652
Epoch 54, global_step 138400, average loss: 0.06313926318594895
Epoch 54, global_step 138500, average loss: 0.1030792689766895
Epoch 54, global_step 138600, average loss: 0.09814876140630076
Epoch 54, global_step 138700, average loss: 0.10849625554532395
Epoch 54, global_step 138800, average loss: 0.0516255154182727
Epoch 54, global_step 138900, average loss: 0.09727958042094542
Epoch 54, global_step 139000, average loss: 0.09733291701493726
Epoch 54, global_step 139100, average loss: 0.09054551595625526
Epoch 54, global_step 139200, average loss: 0.0823593657325182
Epoch 54, global_step 139300, average loss: 0.03471113087351114
Epoch 54, global_step 139400, average loss: 0.061565608810706184
Epoch 54, global_step 139500, average loss: 0.1217594107307741
Epoch 54, global_step 139600, average loss: 0.05010244240584143
Epoch 54, global_step 139700, average loss: 0.13059322997316486
Epoch 54, global_step 139800, average loss: 0.056912686505820605
Epoch 54, global_step 139900, average loss: 0.07156218674546835
Epoch 54, global_step 140000, average loss: 0.018640685916034273
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8906
Valid loss 0.4653141737168312  -  Best loss 0.3913421481334113 at step 130000
Epoch 54, global_step 140100, average loss: 0.15224286313434277
Epoch 54, global_step 140200, average loss: 0.05868974185174011
Epoch 54, global_step 140300, average loss: 0.08340685105493321
Epoch 54, global_step 140400, average loss: 0.12518218937828351
Epoch 54, global_step 140500, average loss: 0.06999284836532751
Epoch 54, global_step 140600, average loss: 0.08785388130872888
Epoch 54, global_step 140700, average loss: 0.10732595611025317
Epoch 54, global_step 140800, average loss: 0.11307768859849603
Epoch 55, global_step 140900, average loss: 0.07656321448077506
Epoch 55, global_step 141000, average loss: 0.06223095744247985
Epoch 55, global_step 141100, average loss: 0.08218605016896617
Epoch 55, global_step 141200, average loss: 0.07003518199388054
Epoch 55, global_step 141300, average loss: 0.043819993689612605
Epoch 55, global_step 141400, average loss: 0.10429571222714003
Epoch 55, global_step 141500, average loss: 0.09060617989409366
Epoch 55, global_step 141600, average loss: 0.058221990370584537
Epoch 55, global_step 141700, average loss: 0.0854657419313662
Epoch 55, global_step 141800, average loss: 0.12431525706535468
Epoch 55, global_step 141900, average loss: 0.1326378197667873
Epoch 55, global_step 142000, average loss: 0.09089372936974542
Epoch 55, global_step 142100, average loss: 0.09975575132160884
Epoch 55, global_step 142200, average loss: 0.0984298644609953
Epoch 55, global_step 142300, average loss: 0.05974497150822572
Epoch 55, global_step 142400, average loss: 0.10032540409876674
Epoch 55, global_step 142500, average loss: 0.16008911171786167
Epoch 55, global_step 142600, average loss: 0.0646257891512505
Epoch 55, global_step 142700, average loss: 0.12032916165248025
Epoch 55, global_step 142800, average loss: 0.05771920977484115
Epoch 55, global_step 142900, average loss: 0.11078393488503935
Epoch 55, global_step 143000, average loss: 0.11251149006191553
Epoch 55, global_step 143100, average loss: 0.0909436381876003
Epoch 55, global_step 143200, average loss: 0.11832434808191465
Epoch 55, global_step 143300, average loss: 0.11958847545189201
Epoch 56, global_step 143400, average loss: 0.06492583894902054
Epoch 56, global_step 143500, average loss: 0.06464676782343304
Epoch 56, global_step 143600, average loss: 0.0803664334064888
Epoch 56, global_step 143700, average loss: 0.08881444128044677
Epoch 56, global_step 143800, average loss: 0.10536422618082725
Epoch 56, global_step 143900, average loss: 0.1000859344334458
Epoch 56, global_step 144000, average loss: 0.1280008644078407
Epoch 56, global_step 144100, average loss: 0.18994958223029243
Epoch 56, global_step 144200, average loss: 0.07267107893625507
Epoch 56, global_step 144300, average loss: 0.10432688362721819
Epoch 56, global_step 144400, average loss: 0.06704749573567824
Epoch 56, global_step 144500, average loss: 0.07956793831075629
Epoch 56, global_step 144600, average loss: 0.13091908640704786
Epoch 56, global_step 144700, average loss: 0.10361470936790283
Epoch 56, global_step 144800, average loss: 0.07407209856966801
Epoch 56, global_step 144900, average loss: 0.09097334145473723
Epoch 56, global_step 145000, average loss: 0.10160137870450853
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8932
Valid loss 0.40238545262691894  -  Best loss 0.3913421481334113 at step 130000
Epoch 56, global_step 145100, average loss: 0.12145517833378108
Epoch 56, global_step 145200, average loss: 0.125584485557265
Epoch 56, global_step 145300, average loss: 0.10120985196321271
Epoch 56, global_step 145400, average loss: 0.11016803054473712
Epoch 56, global_step 145500, average loss: 0.09279380277876044
Epoch 56, global_step 145600, average loss: 0.13372624020150398
Epoch 56, global_step 145700, average loss: 0.09507045738857414
Epoch 56, global_step 145800, average loss: 0.12433704422845039
Epoch 56, global_step 145900, average loss: 0.05539286334744247
Epoch 57, global_step 146000, average loss: 0.05865148485740065
Epoch 57, global_step 146100, average loss: 0.053437531469899116
Epoch 57, global_step 146200, average loss: 0.0439320032629621
Epoch 57, global_step 146300, average loss: 0.08872776787437033
Epoch 57, global_step 146400, average loss: 0.07737804738775594
Epoch 57, global_step 146500, average loss: 0.050328889822558266
Epoch 57, global_step 146600, average loss: 0.05942181685248215
Epoch 57, global_step 146700, average loss: 0.0584597388021939
Epoch 57, global_step 146800, average loss: 0.0785265470782906
Epoch 57, global_step 146900, average loss: 0.07560649357634247
Epoch 57, global_step 147000, average loss: 0.1383554277409712
Epoch 57, global_step 147100, average loss: 0.10822010134164885
Epoch 57, global_step 147200, average loss: 0.12644038808648475
Epoch 57, global_step 147300, average loss: 0.10978200978097448
Epoch 57, global_step 147400, average loss: 0.09881236549197638
Epoch 57, global_step 147500, average loss: 0.08849811506785045
Epoch 57, global_step 147600, average loss: 0.08326966624408669
Epoch 57, global_step 147700, average loss: 0.08818383296296815
Epoch 57, global_step 147800, average loss: 0.09199357486533699
Epoch 57, global_step 147900, average loss: 0.09690033658866014
Epoch 57, global_step 148000, average loss: 0.11022863869446155
Epoch 57, global_step 148100, average loss: 0.12768002540884482
Epoch 57, global_step 148200, average loss: 0.09941573463889654
Epoch 57, global_step 148300, average loss: 0.0915837812051177
Epoch 57, global_step 148400, average loss: 0.08393787440596498
Epoch 58, global_step 148500, average loss: 0.13121290628594579
Epoch 58, global_step 148600, average loss: 0.09619689389364794
Epoch 58, global_step 148700, average loss: 0.07256258623521716
Epoch 58, global_step 148800, average loss: 0.08989008458716853
Epoch 58, global_step 148900, average loss: 0.09480625403302838
Epoch 58, global_step 149000, average loss: 0.075472654060286
Epoch 58, global_step 149100, average loss: 0.09551457915753417
Epoch 58, global_step 149200, average loss: 0.04531877838242508
Epoch 58, global_step 149300, average loss: 0.061881430161083696
Epoch 58, global_step 149400, average loss: 0.044535258195828646
Epoch 58, global_step 149500, average loss: 0.13663557668471185
Epoch 58, global_step 149600, average loss: 0.08703180126321967
Epoch 58, global_step 149700, average loss: 0.08517238723543415
Epoch 58, global_step 149800, average loss: 0.06608812138743815
Epoch 58, global_step 149900, average loss: 0.07314066561499204
Epoch 58, global_step 150000, average loss: 0.08659007963382465
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8906
Valid loss 0.44739780645409305  -  Best loss 0.3913421481334113 at step 130000
Epoch 58, global_step 150100, average loss: 0.04943358162483492
Epoch 58, global_step 150200, average loss: 0.12637294671432756
Epoch 58, global_step 150300, average loss: 0.057040736494673186
Epoch 58, global_step 150400, average loss: 0.056665642597654366
Epoch 58, global_step 150500, average loss: 0.12603320018824887
Epoch 58, global_step 150600, average loss: 0.08992336099974636
Epoch 58, global_step 150700, average loss: 0.09434450786218804
Epoch 58, global_step 150800, average loss: 0.13113619048468536
Epoch 58, global_step 150900, average loss: 0.05945682131350623
Epoch 58, global_step 151000, average loss: 0.09976917342421075
Epoch 59, global_step 151100, average loss: 0.06841572747085593
Epoch 59, global_step 151200, average loss: 0.11643557837007393
Epoch 59, global_step 151300, average loss: 0.06431763502063405
Epoch 59, global_step 151400, average loss: 0.08405401898431591
Epoch 59, global_step 151500, average loss: 0.04342496948091139
Epoch 59, global_step 151600, average loss: 0.07353765417283284
Epoch 59, global_step 151700, average loss: 0.06362968213637941
Epoch 59, global_step 151800, average loss: 0.0721472359206382
Epoch 59, global_step 151900, average loss: 0.0800145500630606
Epoch 59, global_step 152000, average loss: 0.05873440118142753
Epoch 59, global_step 152100, average loss: 0.11814247685280861
Epoch 59, global_step 152200, average loss: 0.10600432431681839
Epoch 59, global_step 152300, average loss: 0.09447941174883454
Epoch 59, global_step 152400, average loss: 0.0867818490514037
Epoch 59, global_step 152500, average loss: 0.09835949785832782
Epoch 59, global_step 152600, average loss: 0.05838057224034856
Epoch 59, global_step 152700, average loss: 0.08272871047709486
Epoch 59, global_step 152800, average loss: 0.10608502630740986
Epoch 59, global_step 152900, average loss: 0.13045287356399057
Epoch 59, global_step 153000, average loss: 0.132938668752613
Epoch 59, global_step 153100, average loss: 0.0891711456370831
Epoch 59, global_step 153200, average loss: 0.08039357435853162
Epoch 59, global_step 153300, average loss: 0.10918639880808768
Epoch 59, global_step 153400, average loss: 0.09670111304651073
Epoch 59, global_step 153500, average loss: 0.09262076182261808
Epoch 59, global_step 153600, average loss: 0.07006959595746594
Epoch 60, global_step 153700, average loss: 0.06919070532348996
Epoch 60, global_step 153800, average loss: 0.06995011097882525
Epoch 60, global_step 153900, average loss: 0.08120315895845125
Epoch 60, global_step 154000, average loss: 0.07255756431462941
Epoch 60, global_step 154100, average loss: 0.03512253628949111
Epoch 60, global_step 154200, average loss: 0.04207955302365008
Epoch 60, global_step 154300, average loss: 0.06953977305412991
Epoch 60, global_step 154400, average loss: 0.08967829414614244
Epoch 60, global_step 154500, average loss: 0.06936245687946212
Epoch 60, global_step 154600, average loss: 0.02119650229928084
Epoch 60, global_step 154700, average loss: 0.0791676238871878
Epoch 60, global_step 154800, average loss: 0.06936364879140455
Epoch 60, global_step 154900, average loss: 0.10254021972716146
Epoch 60, global_step 155000, average loss: 0.06601766268744541
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8885
Valid loss 0.5025981132166463  -  Best loss 0.3913421481334113 at step 130000
Epoch 60, global_step 155100, average loss: 0.0693301770927792
Epoch 60, global_step 155200, average loss: 0.11938693568270536
Epoch 60, global_step 155300, average loss: 0.19842053953252617
Epoch 60, global_step 155400, average loss: 0.04881624638663198
Epoch 60, global_step 155500, average loss: 0.08785166895424482
Epoch 60, global_step 155600, average loss: 0.11205366631089418
Epoch 60, global_step 155700, average loss: 0.14340490821508867
Epoch 60, global_step 155800, average loss: 0.09644959096709499
Epoch 60, global_step 155900, average loss: 0.09551899752819736
Epoch 60, global_step 156000, average loss: 0.1192454990666738
Epoch 60, global_step 156100, average loss: 0.10780265661815065
save checkpoint at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint/epoch60
Epoch 61, global_step 156200, average loss: 0.08992009841844265
Epoch 61, global_step 156300, average loss: 0.059408161068495245
Epoch 61, global_step 156400, average loss: 0.05660308882768732
Epoch 61, global_step 156500, average loss: 0.09782959408090391
Epoch 61, global_step 156600, average loss: 0.09947740395095024
Epoch 61, global_step 156700, average loss: 0.09448489286041876
Epoch 61, global_step 156800, average loss: 0.0709001359109243
Epoch 61, global_step 156900, average loss: 0.08720874819759046
Epoch 61, global_step 157000, average loss: 0.0768008556705172
Epoch 61, global_step 157100, average loss: 0.13197874797777331
Epoch 61, global_step 157200, average loss: 0.07212093893511337
Epoch 61, global_step 157300, average loss: 0.07687440669229545
Epoch 61, global_step 157400, average loss: 0.07312079799070488
Epoch 61, global_step 157500, average loss: 0.07266527498832147
Epoch 61, global_step 157600, average loss: 0.0744632854918018
Epoch 61, global_step 157700, average loss: 0.11486038165814534
Epoch 61, global_step 157800, average loss: 0.058612299936212364
Epoch 61, global_step 157900, average loss: 0.07950964495510561
Epoch 61, global_step 158000, average loss: 0.06113724555150839
Epoch 61, global_step 158100, average loss: 0.13258164944127201
Epoch 61, global_step 158200, average loss: 0.09484191619398188
Epoch 61, global_step 158300, average loss: 0.10351753075701708
Epoch 61, global_step 158400, average loss: 0.08704764466339839
Epoch 61, global_step 158500, average loss: 0.09093885318921821
Epoch 61, global_step 158600, average loss: 0.15545513535027566
Epoch 61, global_step 158700, average loss: 0.10668431469639472
Epoch 62, global_step 158800, average loss: 0.07076277893451334
Epoch 62, global_step 158900, average loss: 0.08274712040991289
Epoch 62, global_step 159000, average loss: 0.08817984709567099
Epoch 62, global_step 159100, average loss: 0.07478061626716226
Epoch 62, global_step 159200, average loss: 0.05375149977742694
Epoch 62, global_step 159300, average loss: 0.10451697737655195
Epoch 62, global_step 159400, average loss: 0.07914196891382744
Epoch 62, global_step 159500, average loss: 0.05818493153186864
Epoch 62, global_step 159600, average loss: 0.07004017413004476
Epoch 62, global_step 159700, average loss: 0.10197891906493169
Epoch 62, global_step 159800, average loss: 0.10454693632404087
Epoch 62, global_step 159900, average loss: 0.09454513655873598
Epoch 62, global_step 160000, average loss: 0.06963320068032772
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.9021
Best model (step 160000, average valid loss 0.4136140592341132, average valid acc 0.9020833333333333) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.4136140592341132  -  Best loss 0.4136140592341132 at step 160000
Epoch 62, global_step 160100, average loss: 0.08732893252628855
Epoch 62, global_step 160200, average loss: 0.11136405008110159
Epoch 62, global_step 160300, average loss: 0.08496620817975781
Epoch 62, global_step 160400, average loss: 0.07958720338523563
Epoch 62, global_step 160500, average loss: 0.08408270509804425
Epoch 62, global_step 160600, average loss: 0.09470566638512537
Epoch 62, global_step 160700, average loss: 0.09805074552110454
Epoch 62, global_step 160800, average loss: 0.10029286020697327
Epoch 62, global_step 160900, average loss: 0.052620280188930335
Epoch 62, global_step 161000, average loss: 0.11761158763307321
Epoch 62, global_step 161100, average loss: 0.0905327548054629
Epoch 62, global_step 161200, average loss: 0.11524667397039594
Epoch 63, global_step 161300, average loss: 0.12059463783836691
Epoch 63, global_step 161400, average loss: 0.10233581430169579
Epoch 63, global_step 161500, average loss: 0.03196931656151719
Epoch 63, global_step 161600, average loss: 0.05408807745814556
Epoch 63, global_step 161700, average loss: 0.08023952253388415
Epoch 63, global_step 161800, average loss: 0.042688487093910224
Epoch 63, global_step 161900, average loss: 0.10506123391423898
Epoch 63, global_step 162000, average loss: 0.10258714510084246
Epoch 63, global_step 162100, average loss: 0.08899532590105082
Epoch 63, global_step 162200, average loss: 0.07030312710390717
Epoch 63, global_step 162300, average loss: 0.11739473635119793
Epoch 63, global_step 162400, average loss: 0.05694576048503222
Epoch 63, global_step 162500, average loss: 0.05963200101825351
Epoch 63, global_step 162600, average loss: 0.07475400932220509
Epoch 63, global_step 162700, average loss: 0.07110569144460896
Epoch 63, global_step 162800, average loss: 0.07831227246526395
Epoch 63, global_step 162900, average loss: 0.07821319675422274
Epoch 63, global_step 163000, average loss: 0.0538289797683683
Epoch 63, global_step 163100, average loss: 0.09233874291203392
Epoch 63, global_step 163200, average loss: 0.08896673505361832
Epoch 63, global_step 163300, average loss: 0.10513441234004858
Epoch 63, global_step 163400, average loss: 0.09078544301373767
Epoch 63, global_step 163500, average loss: 0.0529541450511897
Epoch 63, global_step 163600, average loss: 0.09413403775877668
Epoch 63, global_step 163700, average loss: 0.0604658948454744
Epoch 63, global_step 163800, average loss: 0.036258720699042894
Epoch 64, global_step 163900, average loss: 0.08339340163838642
Epoch 64, global_step 164000, average loss: 0.03769632207819086
Epoch 64, global_step 164100, average loss: 0.03766081692549051
Epoch 64, global_step 164200, average loss: 0.05374888926118729
Epoch 64, global_step 164300, average loss: 0.09959853387488693
Epoch 64, global_step 164400, average loss: 0.05872190177760785
Epoch 64, global_step 164500, average loss: 0.030244786704060972
Epoch 64, global_step 164600, average loss: 0.0694437299209676
Epoch 64, global_step 164700, average loss: 0.08794637372644502
Epoch 64, global_step 164800, average loss: 0.05647438607338699
Epoch 64, global_step 164900, average loss: 0.09175154962700617
Epoch 64, global_step 165000, average loss: 0.04929518759847269
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8906
Valid loss 0.4615439891093797  -  Best loss 0.4136140592341132 at step 160000
Epoch 64, global_step 165100, average loss: 0.09116682997257158
Epoch 64, global_step 165200, average loss: 0.10931751660340523
Epoch 64, global_step 165300, average loss: 0.09751956914049514
Epoch 64, global_step 165400, average loss: 0.043987482985903624
Epoch 64, global_step 165500, average loss: 0.08426205471594585
Epoch 64, global_step 165600, average loss: 0.06077565629690071
Epoch 64, global_step 165700, average loss: 0.09905324224760989
Epoch 64, global_step 165800, average loss: 0.0920316332828952
Epoch 64, global_step 165900, average loss: 0.08379659466270822
Epoch 64, global_step 166000, average loss: 0.11675864779695985
Epoch 64, global_step 166100, average loss: 0.09625648558903777
Epoch 64, global_step 166200, average loss: 0.08450665000709705
Epoch 64, global_step 166300, average loss: 0.05084606179327238
Epoch 64, global_step 166400, average loss: 0.12885867816636165
Epoch 65, global_step 166500, average loss: 0.07096703375653306
Epoch 65, global_step 166600, average loss: 0.07048492124631593
Epoch 65, global_step 166700, average loss: 0.06225969256920507
Epoch 65, global_step 166800, average loss: 0.06260245429286443
Epoch 65, global_step 166900, average loss: 0.07601847368277959
Epoch 65, global_step 167000, average loss: 0.035780800892971455
Epoch 65, global_step 167100, average loss: 0.03642556476908794
Epoch 65, global_step 167200, average loss: 0.05595879008578777
Epoch 65, global_step 167300, average loss: 0.0418381207803759
Epoch 65, global_step 167400, average loss: 0.12420058892574161
Epoch 65, global_step 167500, average loss: 0.0173425018414855
Epoch 65, global_step 167600, average loss: 0.04823890367340937
Epoch 65, global_step 167700, average loss: 0.091119607533401
Epoch 65, global_step 167800, average loss: 0.030726621920839536
Epoch 65, global_step 167900, average loss: 0.0701822478115355
Epoch 65, global_step 168000, average loss: 0.11493545704957796
Epoch 65, global_step 168100, average loss: 0.07559784478944494
Epoch 65, global_step 168200, average loss: 0.13436321446017246
Epoch 65, global_step 168300, average loss: 0.09493727189350466
Epoch 65, global_step 168400, average loss: 0.10569555135152768
Epoch 65, global_step 168500, average loss: 0.06423141926308745
Epoch 65, global_step 168600, average loss: 0.08561424780993548
Epoch 65, global_step 168700, average loss: 0.09742072042776272
Epoch 65, global_step 168800, average loss: 0.07922952926921425
Epoch 65, global_step 168900, average loss: 0.058150787747945284
Epoch 66, global_step 169000, average loss: 0.07680140263684734
Epoch 66, global_step 169100, average loss: 0.0693509713448293
Epoch 66, global_step 169200, average loss: 0.06478876342363947
Epoch 66, global_step 169300, average loss: 0.07565225186590396
Epoch 66, global_step 169400, average loss: 0.09126693933278147
Epoch 66, global_step 169500, average loss: 0.07585662636054621
Epoch 66, global_step 169600, average loss: 0.06631470557964349
Epoch 66, global_step 169700, average loss: 0.04887501941280789
Epoch 66, global_step 169800, average loss: 0.053021426354462164
Epoch 66, global_step 169900, average loss: 0.09751238675453351
Epoch 66, global_step 170000, average loss: 0.06181947776072775
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8958
Valid loss 0.5378704850372474  -  Best loss 0.4136140592341132 at step 160000
Epoch 66, global_step 170100, average loss: 0.12165359214894124
Epoch 66, global_step 170200, average loss: 0.11332341533619911
Epoch 66, global_step 170300, average loss: 0.0608329765178496
Epoch 66, global_step 170400, average loss: 0.10908154260047014
Epoch 66, global_step 170500, average loss: 0.012557485290963087
Epoch 66, global_step 170600, average loss: 0.07506360667881382
Epoch 66, global_step 170700, average loss: 0.13054757009987952
Epoch 66, global_step 170800, average loss: 0.059826088205882116
Epoch 66, global_step 170900, average loss: 0.08509029923632624
Epoch 66, global_step 171000, average loss: 0.07699104832710874
Epoch 66, global_step 171100, average loss: 0.09850615348201246
Epoch 66, global_step 171200, average loss: 0.08868899114859233
Epoch 66, global_step 171300, average loss: 0.06695850116710061
Epoch 66, global_step 171400, average loss: 0.09496764677460305
Epoch 66, global_step 171500, average loss: 0.08731492179853376
Epoch 67, global_step 171600, average loss: 0.12545751015008136
Epoch 67, global_step 171700, average loss: 0.0771101003199874
Epoch 67, global_step 171800, average loss: 0.0353589056005876
Epoch 67, global_step 171900, average loss: 0.06418999768051435
Epoch 67, global_step 172000, average loss: 0.054321988120427704
Epoch 67, global_step 172100, average loss: 0.050382187510113
Epoch 67, global_step 172200, average loss: 0.09358078861194372
Epoch 67, global_step 172300, average loss: 0.06524272859904158
Epoch 67, global_step 172400, average loss: 0.07900195189948135
Epoch 67, global_step 172500, average loss: 0.04521495861590665
Epoch 67, global_step 172600, average loss: 0.14525510868974378
Epoch 67, global_step 172700, average loss: 0.09517633444353123
Epoch 67, global_step 172800, average loss: 0.07595760994845477
Epoch 67, global_step 172900, average loss: 0.06310641089192359
Epoch 67, global_step 173000, average loss: 0.04040192847103754
Epoch 67, global_step 173100, average loss: 0.05788400998913858
Epoch 67, global_step 173200, average loss: 0.06623368237509566
Epoch 67, global_step 173300, average loss: 0.09504903064887912
Epoch 67, global_step 173400, average loss: 0.0979609544766572
Epoch 67, global_step 173500, average loss: 0.12813507080922137
Epoch 67, global_step 173600, average loss: 0.13598250582886975
Epoch 67, global_step 173700, average loss: 0.09436657665828534
Epoch 67, global_step 173800, average loss: 0.07030351944587893
Epoch 67, global_step 173900, average loss: 0.13574336107150883
Epoch 67, global_step 174000, average loss: 0.08262108775270463
Epoch 68, global_step 174100, average loss: 0.0965664704721712
Epoch 68, global_step 174200, average loss: 0.05178420859658218
Epoch 68, global_step 174300, average loss: 0.06305043854852556
Epoch 68, global_step 174400, average loss: 0.05151581845217151
Epoch 68, global_step 174500, average loss: 0.0686827006146632
Epoch 68, global_step 174600, average loss: 0.04569200739133521
Epoch 68, global_step 174700, average loss: 0.07705564706520818
Epoch 68, global_step 174800, average loss: 0.0783988689185935
Epoch 68, global_step 174900, average loss: 0.10737693141440104
Epoch 68, global_step 175000, average loss: 0.06514563482865925
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8964
Valid loss 0.5303614086745182  -  Best loss 0.4136140592341132 at step 160000
Epoch 68, global_step 175100, average loss: 0.13091662852923036
Epoch 68, global_step 175200, average loss: 0.07341751490595926
Epoch 68, global_step 175300, average loss: 0.07207874004168843
Epoch 68, global_step 175400, average loss: 0.03549551302261534
Epoch 68, global_step 175500, average loss: 0.09802106055161858
Epoch 68, global_step 175600, average loss: 0.09043300886791257
Epoch 68, global_step 175700, average loss: 0.09180847812720458
Epoch 68, global_step 175800, average loss: 0.07422011077258503
Epoch 68, global_step 175900, average loss: 0.0684816291018069
Epoch 68, global_step 176000, average loss: 0.06667692240458564
Epoch 68, global_step 176100, average loss: 0.0822154462452454
Epoch 68, global_step 176200, average loss: 0.1252452569842717
Epoch 68, global_step 176300, average loss: 0.08300779616241925
Epoch 68, global_step 176400, average loss: 0.09294466716171883
Epoch 68, global_step 176500, average loss: 0.09643818513526639
Epoch 68, global_step 176600, average loss: 0.074758044342816
Epoch 69, global_step 176700, average loss: 0.07753121252026177
Epoch 69, global_step 176800, average loss: 0.028281112492331884
Epoch 69, global_step 176900, average loss: 0.050959280451788797
Epoch 69, global_step 177000, average loss: 0.04754112224894925
Epoch 69, global_step 177100, average loss: 0.10179395003826358
Epoch 69, global_step 177200, average loss: 0.12138145718330634
Epoch 69, global_step 177300, average loss: 0.06503521590959281
Epoch 69, global_step 177400, average loss: 0.04823258087883005
Epoch 69, global_step 177500, average loss: 0.0876623255523009
Epoch 69, global_step 177600, average loss: 0.057843460198564574
Epoch 69, global_step 177700, average loss: 0.06674660278855299
Epoch 69, global_step 177800, average loss: 0.09604475805186667
Epoch 69, global_step 177900, average loss: 0.06442308895246242
Epoch 69, global_step 178000, average loss: 0.093202898687814
Epoch 69, global_step 178100, average loss: 0.0986424015842931
Epoch 69, global_step 178200, average loss: 0.09476994322321844
Epoch 69, global_step 178300, average loss: 0.05142447160666052
Epoch 69, global_step 178400, average loss: 0.1005992976044945
Epoch 69, global_step 178500, average loss: 0.10644432153909293
Epoch 69, global_step 178600, average loss: 0.08836237314004393
Epoch 69, global_step 178700, average loss: 0.07762152849303675
Epoch 69, global_step 178800, average loss: 0.08666856101735902
Epoch 69, global_step 178900, average loss: 0.06660102220375848
Epoch 69, global_step 179000, average loss: 0.07608198305817496
Epoch 69, global_step 179100, average loss: 0.05890459939968423
Epoch 69, global_step 179200, average loss: 0.0922581997337693
Epoch 70, global_step 179300, average loss: 0.04102281549698091
Epoch 70, global_step 179400, average loss: 0.05636460120571428
Epoch 70, global_step 179500, average loss: 0.04789694316568784
Epoch 70, global_step 179600, average loss: 0.02190366718758014
Epoch 70, global_step 179700, average loss: 0.02725742609174631
Epoch 70, global_step 179800, average loss: 0.09083658518829907
Epoch 70, global_step 179900, average loss: 0.08919591336692974
Epoch 70, global_step 180000, average loss: 0.06397897129580088
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8849
Valid loss 0.5045427097180226  -  Best loss 0.4136140592341132 at step 160000
Epoch 70, global_step 180100, average loss: 0.08865261476305022
Epoch 70, global_step 180200, average loss: 0.04653916678107635
Epoch 70, global_step 180300, average loss: 0.10533779207005864
Epoch 70, global_step 180400, average loss: 0.11487905896719894
Epoch 70, global_step 180500, average loss: 0.08378025471029105
Epoch 70, global_step 180600, average loss: 0.10874665799783542
Epoch 70, global_step 180700, average loss: 0.046924411512809454
Epoch 70, global_step 180800, average loss: 0.0428198478178092
Epoch 70, global_step 180900, average loss: 0.07173529168263486
Epoch 70, global_step 181000, average loss: 0.06869206906230829
Epoch 70, global_step 181100, average loss: 0.05402447571868833
Epoch 70, global_step 181200, average loss: 0.11473655402769509
Epoch 70, global_step 181300, average loss: 0.06515962814628437
Epoch 70, global_step 181400, average loss: 0.053122739085447394
Epoch 70, global_step 181500, average loss: 0.08200731016862846
Epoch 70, global_step 181600, average loss: 0.08115859388817626
Epoch 70, global_step 181700, average loss: 0.10116988736343047
Epoch 71, global_step 181800, average loss: 0.12796478486343404
Epoch 71, global_step 181900, average loss: 0.07556398080690997
Epoch 71, global_step 182000, average loss: 0.05307118733311654
Epoch 71, global_step 182100, average loss: 0.06549754797422792
Epoch 71, global_step 182200, average loss: 0.08195313857853762
Epoch 71, global_step 182300, average loss: 0.0364406040564063
Epoch 71, global_step 182400, average loss: 0.11647203553962754
Epoch 71, global_step 182500, average loss: 0.05246127100923331
Epoch 71, global_step 182600, average loss: 0.06861545434796426
Epoch 71, global_step 182700, average loss: 0.03333263107146195
Epoch 71, global_step 182800, average loss: 0.13453163456171752
Epoch 71, global_step 182900, average loss: 0.08259477161816903
Epoch 71, global_step 183000, average loss: 0.08214112551155267
Epoch 71, global_step 183100, average loss: 0.10154008225385042
Epoch 71, global_step 183200, average loss: 0.10110760260446114
Epoch 71, global_step 183300, average loss: 0.09883930234078435
Epoch 71, global_step 183400, average loss: 0.06509443130657018
Epoch 71, global_step 183500, average loss: 0.09673256668800605
Epoch 71, global_step 183600, average loss: 0.059609847582105434
Epoch 71, global_step 183700, average loss: 0.06548147741319553
Epoch 71, global_step 183800, average loss: 0.1161711428048875
Epoch 71, global_step 183900, average loss: 0.06106781530535955
Epoch 71, global_step 184000, average loss: 0.12198647424054798
Epoch 71, global_step 184100, average loss: 0.09173984327382641
Epoch 71, global_step 184200, average loss: 0.02504691842594184
Epoch 71, global_step 184300, average loss: 0.046580572870152534
Epoch 72, global_step 184400, average loss: 0.07625987245890428
Epoch 72, global_step 184500, average loss: 0.0194862205604295
Epoch 72, global_step 184600, average loss: 0.08860263294707693
Epoch 72, global_step 184700, average loss: 0.10509469172699028
Epoch 72, global_step 184800, average loss: 0.03645376090207719
Epoch 72, global_step 184900, average loss: 0.06172443310410017
Epoch 72, global_step 185000, average loss: 0.03187439418223221
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8927
Valid loss 0.5168211147871894  -  Best loss 0.4136140592341132 at step 160000
Epoch 72, global_step 185100, average loss: 0.07063914620564901
Epoch 72, global_step 185200, average loss: 0.07422173764600302
Epoch 72, global_step 185300, average loss: 0.05583866647924879
Epoch 72, global_step 185400, average loss: 0.05844267177330039
Epoch 72, global_step 185500, average loss: 0.0608308064652374
Epoch 72, global_step 185600, average loss: 0.11169258598638407
Epoch 72, global_step 185700, average loss: 0.06284459185735614
Epoch 72, global_step 185800, average loss: 0.04744653752968588
Epoch 72, global_step 185900, average loss: 0.11355959927830554
Epoch 72, global_step 186000, average loss: 0.06549607068263867
Epoch 72, global_step 186100, average loss: 0.09307132695124892
Epoch 72, global_step 186200, average loss: 0.09982994869438698
Epoch 72, global_step 186300, average loss: 0.10793066105419712
Epoch 72, global_step 186400, average loss: 0.05707238116345252
Epoch 72, global_step 186500, average loss: 0.06486457172948576
Epoch 72, global_step 186600, average loss: 0.05742822794374661
Epoch 72, global_step 186700, average loss: 0.04180805721851357
Epoch 72, global_step 186800, average loss: 0.07448204446409364
Epoch 73, global_step 186900, average loss: 0.09185610974098381
Epoch 73, global_step 187000, average loss: 0.10051606385612104
Epoch 73, global_step 187100, average loss: 0.07182487234764266
Epoch 73, global_step 187200, average loss: 0.11251832134148572
Epoch 73, global_step 187300, average loss: 0.08344707871008722
Epoch 73, global_step 187400, average loss: 0.05835091507440666
Epoch 73, global_step 187500, average loss: 0.06968780572882678
Epoch 73, global_step 187600, average loss: 0.051099439056779376
Epoch 73, global_step 187700, average loss: 0.032316883184175825
Epoch 73, global_step 187800, average loss: 0.07643592600339616
Epoch 73, global_step 187900, average loss: 0.08798689801697038
Epoch 73, global_step 188000, average loss: 0.07688675021439849
Epoch 73, global_step 188100, average loss: 0.12154842603747966
Epoch 73, global_step 188200, average loss: 0.07535445394183625
Epoch 73, global_step 188300, average loss: 0.08487317394850834
Epoch 73, global_step 188400, average loss: 0.04683336373214843
Epoch 73, global_step 188500, average loss: 0.060359203109546795
Epoch 73, global_step 188600, average loss: 0.0451184190208005
Epoch 73, global_step 188700, average loss: 0.08983243437156489
Epoch 73, global_step 188800, average loss: 0.06970338525352418
Epoch 73, global_step 188900, average loss: 0.09102315467505832
Epoch 73, global_step 189000, average loss: 0.05506824656564277
Epoch 73, global_step 189100, average loss: 0.04618763566999405
Epoch 73, global_step 189200, average loss: 0.10478887825462152
Epoch 73, global_step 189300, average loss: 0.0989881020088069
Epoch 73, global_step 189400, average loss: 0.10208714429340034
Epoch 74, global_step 189500, average loss: 0.07521843600734428
Epoch 74, global_step 189600, average loss: 0.05652115573742776
Epoch 74, global_step 189700, average loss: 0.057745483840553787
Epoch 74, global_step 189800, average loss: 0.04954384671895241
Epoch 74, global_step 189900, average loss: 0.06597932283606496
Epoch 74, global_step 190000, average loss: 0.030459941143126345
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8917
Valid loss 0.49253488019275826  -  Best loss 0.4136140592341132 at step 160000
Epoch 74, global_step 190100, average loss: 0.06876195442615426
Epoch 74, global_step 190200, average loss: 0.06440123877218866
Epoch 74, global_step 190300, average loss: 0.043834992783522465
Epoch 74, global_step 190400, average loss: 0.07795449338758771
Epoch 74, global_step 190500, average loss: 0.07909951885601912
Epoch 74, global_step 190600, average loss: 0.0879914853660739
Epoch 74, global_step 190700, average loss: 0.08477321068239689
Epoch 74, global_step 190800, average loss: 0.057621588978145157
Epoch 74, global_step 190900, average loss: 0.052456372930755606
Epoch 74, global_step 191000, average loss: 0.11213697532875813
Epoch 74, global_step 191100, average loss: 0.05456946992482699
Epoch 74, global_step 191200, average loss: 0.08674369592772564
Epoch 74, global_step 191300, average loss: 0.07752234081766801
Epoch 74, global_step 191400, average loss: 0.06864726982566935
Epoch 74, global_step 191500, average loss: 0.04353880391601706
Epoch 74, global_step 191600, average loss: 0.10473709240264725
Epoch 74, global_step 191700, average loss: 0.11829359047100298
Epoch 74, global_step 191800, average loss: 0.0732238471150049
Epoch 74, global_step 191900, average loss: 0.10340908310536179
Epoch 74, global_step 192000, average loss: 0.06550969468393304
Epoch 75, global_step 192100, average loss: 0.09040498921393009
Epoch 75, global_step 192200, average loss: 0.04625318581711326
Epoch 75, global_step 192300, average loss: 0.06613681705777708
Epoch 75, global_step 192400, average loss: 0.044487912248805515
Epoch 75, global_step 192500, average loss: 0.0421478586721787
Epoch 75, global_step 192600, average loss: 0.09502919097642007
Epoch 75, global_step 192700, average loss: 0.07548022815099102
Epoch 75, global_step 192800, average loss: 0.04802140241859888
Epoch 75, global_step 192900, average loss: 0.06783798827629653
Epoch 75, global_step 193000, average loss: 0.04888307237786648
Epoch 75, global_step 193100, average loss: 0.07622896250089979
Epoch 75, global_step 193200, average loss: 0.09348331104876706
Epoch 75, global_step 193300, average loss: 0.06797028576205776
Epoch 75, global_step 193400, average loss: 0.08808596047208994
Epoch 75, global_step 193500, average loss: 0.05852180353780568
Epoch 75, global_step 193600, average loss: 0.048595588912139644
Epoch 75, global_step 193700, average loss: 0.07933224978834914
Epoch 75, global_step 193800, average loss: 0.08040004537571804
Epoch 75, global_step 193900, average loss: 0.11710489691984549
Epoch 75, global_step 194000, average loss: 0.028049130668659928
Epoch 75, global_step 194100, average loss: 0.05033702526307025
Epoch 75, global_step 194200, average loss: 0.12543912816290687
Epoch 75, global_step 194300, average loss: 0.0736227904491534
Epoch 75, global_step 194400, average loss: 0.07344829976129404
Epoch 75, global_step 194500, average loss: 0.08562080306139251
Epoch 76, global_step 194600, average loss: 0.02531333497048763
Epoch 76, global_step 194700, average loss: 0.04541825740794593
Epoch 76, global_step 194800, average loss: 0.4563432770268264
Epoch 76, global_step 194900, average loss: 0.054559632642412904
Epoch 76, global_step 195000, average loss: 0.04975342785277462
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8953
Valid loss 0.6071951322953051  -  Best loss 0.4136140592341132 at step 160000
Epoch 76, global_step 195100, average loss: 0.08081216905571637
Epoch 76, global_step 195200, average loss: 0.07359854371665278
Epoch 76, global_step 195300, average loss: 0.16007330946253207
Epoch 76, global_step 195400, average loss: 0.05064682953125157
Epoch 76, global_step 195500, average loss: 0.07593554107035744
Epoch 76, global_step 195600, average loss: 0.07546033124781389
Epoch 76, global_step 195700, average loss: 0.07512009166843199
Epoch 76, global_step 195800, average loss: 0.060815890667872734
Epoch 76, global_step 195900, average loss: 0.20193481663613055
Epoch 76, global_step 196000, average loss: 0.10359379408335372
Epoch 76, global_step 196100, average loss: 0.08427870077612169
Epoch 76, global_step 196200, average loss: 0.09282277438214806
Epoch 76, global_step 196300, average loss: 0.0788316814238351
Epoch 76, global_step 196400, average loss: 0.17383164336031767
Epoch 76, global_step 196500, average loss: 0.0661408729476534
Epoch 76, global_step 196600, average loss: 0.07841845900256886
Epoch 76, global_step 196700, average loss: 0.06275035227612534
Epoch 76, global_step 196800, average loss: 0.08377158108283765
Epoch 76, global_step 196900, average loss: 0.11422208978350681
Epoch 76, global_step 197000, average loss: 0.06376691738842055
Epoch 76, global_step 197100, average loss: 0.0625048412198521
Epoch 77, global_step 197200, average loss: 0.050636923928759646
Epoch 77, global_step 197300, average loss: 0.04681040895629849
Epoch 77, global_step 197400, average loss: 0.059504061334664585
Epoch 77, global_step 197500, average loss: 0.04326003074798791
Epoch 77, global_step 197600, average loss: 0.04880283987586154
Epoch 77, global_step 197700, average loss: 0.0875380044101621
Epoch 77, global_step 197800, average loss: 0.026929337971450876
Epoch 77, global_step 197900, average loss: 0.11227529133779171
Epoch 77, global_step 198000, average loss: 0.06912521540361923
Epoch 77, global_step 198100, average loss: 0.08093317217353616
Epoch 77, global_step 198200, average loss: 0.05602865568856941
Epoch 77, global_step 198300, average loss: 0.06509157125365164
Epoch 77, global_step 198400, average loss: 0.07074105552426772
Epoch 77, global_step 198500, average loss: 0.07804010003201256
Epoch 77, global_step 198600, average loss: 0.0337436354997044
Epoch 77, global_step 198700, average loss: 0.0995868470724963
Epoch 77, global_step 198800, average loss: 0.09512200652643514
Epoch 77, global_step 198900, average loss: 0.08480221222205728
Epoch 77, global_step 199000, average loss: 0.1142384314078663
Epoch 77, global_step 199100, average loss: 0.06180432144115912
Epoch 77, global_step 199200, average loss: 0.10351947540664697
Epoch 77, global_step 199300, average loss: 0.08694748198562592
Epoch 77, global_step 199400, average loss: 0.1001287374550884
Epoch 77, global_step 199500, average loss: 0.10015772545186337
Epoch 77, global_step 199600, average loss: 0.06509954474342522
Epoch 78, global_step 199700, average loss: 0.043886310088128086
Epoch 78, global_step 199800, average loss: 0.05497978018152935
Epoch 78, global_step 199900, average loss: 0.06510107110429089
Epoch 78, global_step 200000, average loss: 0.023802391231220098
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8906
Valid loss 0.5542533469996324  -  Best loss 0.4136140592341132 at step 160000
Epoch 78, global_step 200100, average loss: 0.08467557563773881
Epoch 78, global_step 200200, average loss: 0.026165594950143714
Epoch 78, global_step 200300, average loss: 0.07240193353049108
Epoch 78, global_step 200400, average loss: 0.05493684269604273
Epoch 78, global_step 200500, average loss: 0.08767894142896694
Epoch 78, global_step 200600, average loss: 0.10686642177694011
Epoch 78, global_step 200700, average loss: 0.09698249188470072
Epoch 78, global_step 200800, average loss: 0.025195283224747983
Epoch 78, global_step 200900, average loss: 0.119027594520594
Epoch 78, global_step 201000, average loss: 0.03555899682687595
Epoch 78, global_step 201100, average loss: 0.028266351010024664
Epoch 78, global_step 201200, average loss: 0.0679523912883451
Epoch 78, global_step 201300, average loss: 0.04593314063415164
Epoch 78, global_step 201400, average loss: 0.05429083301220089
Epoch 78, global_step 201500, average loss: 0.09503024654848559
Epoch 78, global_step 201600, average loss: 0.10337736892492103
Epoch 78, global_step 201700, average loss: 0.13111436355145997
Epoch 78, global_step 201800, average loss: 0.08847202502787695
Epoch 78, global_step 201900, average loss: 0.0667130563511455
Epoch 78, global_step 202000, average loss: 0.1157926853083336
Epoch 78, global_step 202100, average loss: 0.0811424737120251
Epoch 78, global_step 202200, average loss: 0.07118559448717861
Epoch 79, global_step 202300, average loss: 0.05744372621004004
Epoch 79, global_step 202400, average loss: 0.03125867582115461
Epoch 79, global_step 202500, average loss: 0.05769575250385969
Epoch 79, global_step 202600, average loss: 0.04272250328634982
Epoch 79, global_step 202700, average loss: 0.10642763877520338
Epoch 79, global_step 202800, average loss: 0.031638635220660946
Epoch 79, global_step 202900, average loss: 0.09805800305781304
Epoch 79, global_step 203000, average loss: 0.03553001758620667
Epoch 79, global_step 203100, average loss: 0.04917219312403177
Epoch 79, global_step 203200, average loss: 0.07588267786239157
Epoch 79, global_step 203300, average loss: 0.0455003402102011
Epoch 79, global_step 203400, average loss: 0.054488992044862246
Epoch 79, global_step 203500, average loss: 0.05388963149191113
Epoch 79, global_step 203600, average loss: 0.0442074711289024
Epoch 79, global_step 203700, average loss: 0.02948109251788992
Epoch 79, global_step 203800, average loss: 0.05661689929809654
Epoch 79, global_step 203900, average loss: 0.06421460438650683
Epoch 79, global_step 204000, average loss: 0.09690891605889192
Epoch 79, global_step 204100, average loss: 0.07439682791671658
Epoch 79, global_step 204200, average loss: 0.08791201826803445
Epoch 79, global_step 204300, average loss: 0.05413223103954806
Epoch 79, global_step 204400, average loss: 0.08574051818126463
Epoch 79, global_step 204500, average loss: 0.08532354127717554
Epoch 79, global_step 204600, average loss: 0.06227762347334646
Epoch 79, global_step 204700, average loss: 0.04872682205328602
Epoch 79, global_step 204800, average loss: 0.07772493596552522
Epoch 80, global_step 204900, average loss: 0.155178997023977
Epoch 80, global_step 205000, average loss: 0.07376845095357566
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8880
Valid loss 0.5563261645662756  -  Best loss 0.4136140592341132 at step 160000
Epoch 80, global_step 205100, average loss: 0.07632866186497267
Epoch 80, global_step 205200, average loss: 0.04545430984791892
Epoch 80, global_step 205300, average loss: 0.045589140532829336
Epoch 80, global_step 205400, average loss: 0.05176799661901896
Epoch 80, global_step 205500, average loss: 0.07098433336126618
Epoch 80, global_step 205600, average loss: 0.060856812020065265
Epoch 80, global_step 205700, average loss: 0.05301729159808019
Epoch 80, global_step 205800, average loss: 0.07979466407530708
Epoch 80, global_step 205900, average loss: 0.0510314589132031
Epoch 80, global_step 206000, average loss: 0.03144476249457512
Epoch 80, global_step 206100, average loss: 0.03666502025771479
Epoch 80, global_step 206200, average loss: 0.027035419247695244
Epoch 80, global_step 206300, average loss: 0.04409636864787899
Epoch 80, global_step 206400, average loss: 0.04751186327011965
Epoch 80, global_step 206500, average loss: 0.07796980072918813
Epoch 80, global_step 206600, average loss: 0.07225267972506116
Epoch 80, global_step 206700, average loss: 0.11433635981084081
Epoch 80, global_step 206800, average loss: 0.057225508287738196
Epoch 80, global_step 206900, average loss: 0.12946850690757855
Epoch 80, global_step 207000, average loss: 0.06629763856639329
Epoch 80, global_step 207100, average loss: 0.0533370486820786
Epoch 80, global_step 207200, average loss: 0.05328310601122212
Epoch 80, global_step 207300, average loss: 0.05785867308666639
save checkpoint at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint/epoch80
Epoch 81, global_step 207400, average loss: 0.05246310541406274
Epoch 81, global_step 207500, average loss: 0.030861493118063663
Epoch 81, global_step 207600, average loss: 0.05566546982059663
Epoch 81, global_step 207700, average loss: 0.09803699381147453
Epoch 81, global_step 207800, average loss: 0.04001347044366412
Epoch 81, global_step 207900, average loss: 0.018493029712772113
Epoch 81, global_step 208000, average loss: 0.09255962536924926
Epoch 81, global_step 208100, average loss: 0.07592101125934278
Epoch 81, global_step 208200, average loss: 0.053652397158148235
Epoch 81, global_step 208300, average loss: 0.044094746731498165
Epoch 81, global_step 208400, average loss: 0.1158337337881676
Epoch 81, global_step 208500, average loss: 0.0808802969817043
Epoch 81, global_step 208600, average loss: 0.061349505437901825
Epoch 81, global_step 208700, average loss: 0.06848480547479995
Epoch 81, global_step 208800, average loss: 0.07146397424963652
Epoch 81, global_step 208900, average loss: 0.05775601725516026
Epoch 81, global_step 209000, average loss: 0.03940957896891632
Epoch 81, global_step 209100, average loss: 0.016454439303124672
Epoch 81, global_step 209200, average loss: 0.05859023537595931
Epoch 81, global_step 209300, average loss: 0.07847138075128895
Epoch 81, global_step 209400, average loss: 0.1384008532363805
Epoch 81, global_step 209500, average loss: 0.07234355481807142
Epoch 81, global_step 209600, average loss: 0.09196017806178133
Epoch 81, global_step 209700, average loss: 0.09553280886058929
Epoch 81, global_step 209800, average loss: 0.044501770136193955
Epoch 81, global_step 209900, average loss: 0.036962314037955364
Epoch 82, global_step 210000, average loss: 0.04865280464742682
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8974
Valid loss 0.5941121095133596  -  Best loss 0.4136140592341132 at step 160000
Epoch 82, global_step 210100, average loss: 0.05930155525318696
Epoch 82, global_step 210200, average loss: 0.054773612478747964
Epoch 82, global_step 210300, average loss: 0.05144059094556724
Epoch 82, global_step 210400, average loss: 0.05714028249858529
Epoch 82, global_step 210500, average loss: 0.023941236729224328
Epoch 82, global_step 210600, average loss: 0.039139473082323094
Epoch 82, global_step 210700, average loss: 0.09232208628134686
Epoch 82, global_step 210800, average loss: 0.03363689303630963
Epoch 82, global_step 210900, average loss: 0.044865419630368705
Epoch 82, global_step 211000, average loss: 0.034443780649962716
Epoch 82, global_step 211100, average loss: 0.08000994747286314
Epoch 82, global_step 211200, average loss: 0.02592699787353922
Epoch 82, global_step 211300, average loss: 0.07393653205857845
Epoch 82, global_step 211400, average loss: 0.0941259319398523
Epoch 82, global_step 211500, average loss: 0.0659942754489748
Epoch 82, global_step 211600, average loss: 0.13597098375939823
Epoch 82, global_step 211700, average loss: 0.08127584096437204
Epoch 82, global_step 211800, average loss: 0.062002494241096426
Epoch 82, global_step 211900, average loss: 0.07774017565185204
Epoch 82, global_step 212000, average loss: 0.06130154155558557
Epoch 82, global_step 212100, average loss: 0.05340291995547886
Epoch 82, global_step 212200, average loss: 0.10142231309131602
Epoch 82, global_step 212300, average loss: 0.04865458476677304
Epoch 82, global_step 212400, average loss: 0.04595085285553068
Epoch 83, global_step 212500, average loss: 0.06276951828585879
Epoch 83, global_step 212600, average loss: 0.03898787425554474
Epoch 83, global_step 212700, average loss: 0.04176067404812784
Epoch 83, global_step 212800, average loss: 0.05192438882913848
Epoch 83, global_step 212900, average loss: 0.036896770099701826
Epoch 83, global_step 213000, average loss: 0.07512595050378877
Epoch 83, global_step 213100, average loss: 0.03816313945062575
Epoch 83, global_step 213200, average loss: 0.07574174333778501
Epoch 83, global_step 213300, average loss: 0.07452330644489848
Epoch 83, global_step 213400, average loss: 0.04860342599458818
Epoch 83, global_step 213500, average loss: 0.028387501495162722
Epoch 83, global_step 213600, average loss: 0.03512046896874381
Epoch 83, global_step 213700, average loss: 0.036055038487247656
Epoch 83, global_step 213800, average loss: 0.059849493457149947
Epoch 83, global_step 213900, average loss: 0.035206012079142965
Epoch 83, global_step 214000, average loss: 0.04148091841532733
Epoch 83, global_step 214100, average loss: 0.045209109494098815
Epoch 83, global_step 214200, average loss: 0.05713010108898743
Epoch 83, global_step 214300, average loss: 0.040084805154474455
Epoch 83, global_step 214400, average loss: 0.0848459992253629
Epoch 83, global_step 214500, average loss: 0.04983416081682662
Epoch 83, global_step 214600, average loss: 0.033310846249805764
Epoch 83, global_step 214700, average loss: 0.056359998265543255
Epoch 83, global_step 214800, average loss: 0.08991929714720755
Epoch 83, global_step 214900, average loss: 0.0559324666752218
Epoch 83, global_step 215000, average loss: 0.08941105767924455
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8786
Valid loss 0.5819915691794602  -  Best loss 0.4136140592341132 at step 160000
Epoch 84, global_step 215100, average loss: 0.06767588573260581
Epoch 84, global_step 215200, average loss: 0.1397959345108393
Epoch 84, global_step 215300, average loss: 0.04195788564240502
Epoch 84, global_step 215400, average loss: 0.06459307841512782
Epoch 84, global_step 215500, average loss: 0.039037825842606254
Epoch 84, global_step 215600, average loss: 0.054818761830829316
Epoch 84, global_step 215700, average loss: 0.04856495422784064
Epoch 84, global_step 215800, average loss: 0.0689109589580039
Epoch 84, global_step 215900, average loss: 0.04435531959919899
Epoch 84, global_step 216000, average loss: 0.026652150985610204
Epoch 84, global_step 216100, average loss: 0.06117217625134799
Epoch 84, global_step 216200, average loss: 0.1052071740457177
Epoch 84, global_step 216300, average loss: 0.04537495120370295
Epoch 84, global_step 216400, average loss: 0.051440694941557015
Epoch 84, global_step 216500, average loss: 0.0624611962815834
Epoch 84, global_step 216600, average loss: 0.10125721007760148
Epoch 84, global_step 216700, average loss: 0.07113499704653804
Epoch 84, global_step 216800, average loss: 0.04355336415246711
Epoch 84, global_step 216900, average loss: 0.07130708184376999
Epoch 84, global_step 217000, average loss: 0.0931199114662013
Epoch 84, global_step 217100, average loss: 0.0797667076162179
Epoch 84, global_step 217200, average loss: 0.0694386947692692
Epoch 84, global_step 217300, average loss: 0.06361221310311521
Epoch 84, global_step 217400, average loss: 0.049033393368954424
Epoch 84, global_step 217500, average loss: 0.04413940532016568
Epoch 84, global_step 217600, average loss: 0.0469511251275253
Epoch 85, global_step 217700, average loss: 0.05420972414925927
Epoch 85, global_step 217800, average loss: 0.046241445098494295
Epoch 85, global_step 217900, average loss: 0.050411539873603035
Epoch 85, global_step 218000, average loss: 0.07211629019198881
Epoch 85, global_step 218100, average loss: 0.05755650740713463
Epoch 85, global_step 218200, average loss: 0.025395751912437845
Epoch 85, global_step 218300, average loss: 0.03466144830155827
Epoch 85, global_step 218400, average loss: 0.024668955007728074
Epoch 85, global_step 218500, average loss: 0.08683622505101084
Epoch 85, global_step 218600, average loss: 0.038485786048768206
Epoch 85, global_step 218700, average loss: 0.06766885375793208
Epoch 85, global_step 218800, average loss: 0.08949481999632553
Epoch 85, global_step 218900, average loss: 0.04511654321584501
Epoch 85, global_step 219000, average loss: 0.08674536687409272
Epoch 85, global_step 219100, average loss: 0.032774100557653583
Epoch 85, global_step 219200, average loss: 0.05019875132566085
Epoch 85, global_step 219300, average loss: 0.04369283716463542
Epoch 85, global_step 219400, average loss: 0.039862295502680355
Epoch 85, global_step 219500, average loss: 0.06521229292447969
Epoch 85, global_step 219600, average loss: 0.035530929118831406
Epoch 85, global_step 219700, average loss: 0.06541305414022645
Epoch 85, global_step 219800, average loss: 0.041858644737003486
Epoch 85, global_step 219900, average loss: 0.03893180566839874
Epoch 85, global_step 220000, average loss: 0.043449022391287145
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.9062
Best model (step 220000, average valid loss 0.56046705064323, average valid acc 0.90625) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.56046705064323  -  Best loss 0.56046705064323 at step 220000
Epoch 85, global_step 220100, average loss: 0.05049412292013585
Epoch 86, global_step 220200, average loss: 0.0629638009959308
Epoch 86, global_step 220300, average loss: 0.05372812817891827
Epoch 86, global_step 220400, average loss: 0.05331037873242167
Epoch 86, global_step 220500, average loss: 0.04687655144254677
Epoch 86, global_step 220600, average loss: 0.041712369443412174
Epoch 86, global_step 220700, average loss: 0.030583418503665596
Epoch 86, global_step 220800, average loss: 0.04947133131674491
Epoch 86, global_step 220900, average loss: 0.05248124486330198
Epoch 86, global_step 221000, average loss: 0.06965006397775142
Epoch 86, global_step 221100, average loss: 0.05234133102836495
Epoch 86, global_step 221200, average loss: 0.1340356073142175
Epoch 86, global_step 221300, average loss: 0.10053024814689707
Epoch 86, global_step 221400, average loss: 0.10678319271180953
Epoch 86, global_step 221500, average loss: 0.054074006723167256
Epoch 86, global_step 221600, average loss: 0.08097893966551055
Epoch 86, global_step 221700, average loss: 0.037155431967184994
Epoch 86, global_step 221800, average loss: 0.06580927971328493
Epoch 86, global_step 221900, average loss: 0.07961193637071119
Epoch 86, global_step 222000, average loss: 0.09139313113177196
Epoch 86, global_step 222100, average loss: 0.027450602006210828
Epoch 86, global_step 222200, average loss: 0.15000867312352056
Epoch 86, global_step 222300, average loss: 0.07506267046199355
Epoch 86, global_step 222400, average loss: 0.10508396067496506
Epoch 86, global_step 222500, average loss: 0.10697187955272966
Epoch 86, global_step 222600, average loss: 0.08723994765561656
Epoch 86, global_step 222700, average loss: 0.07803972894696926
Epoch 87, global_step 222800, average loss: 0.1471716395346448
Epoch 87, global_step 222900, average loss: 0.06891911373109906
Epoch 87, global_step 223000, average loss: 0.14107219670630003
Epoch 87, global_step 223100, average loss: 0.058676233731748656
Epoch 87, global_step 223200, average loss: 0.025878172065640682
Epoch 87, global_step 223300, average loss: 0.03409202053961053
Epoch 87, global_step 223400, average loss: 0.07625532893500349
Epoch 87, global_step 223500, average loss: 0.03594303379053599
Epoch 87, global_step 223600, average loss: 0.10235498253452534
Epoch 87, global_step 223700, average loss: 0.10935747417541279
Epoch 87, global_step 223800, average loss: 0.07047067603940377
Epoch 87, global_step 223900, average loss: 0.041922505327747786
Epoch 87, global_step 224000, average loss: 0.06875977851916104
Epoch 87, global_step 224100, average loss: 0.06728363686990634
Epoch 87, global_step 224200, average loss: 0.046962539955275134
Epoch 87, global_step 224300, average loss: 0.04635994412790751
Epoch 87, global_step 224400, average loss: 0.07833467856646166
Epoch 87, global_step 224500, average loss: 0.0830544239419396
Epoch 87, global_step 224600, average loss: 0.04993131019939028
Epoch 87, global_step 224700, average loss: 0.05457117133490101
Epoch 87, global_step 224800, average loss: 0.09034541034554422
Epoch 87, global_step 224900, average loss: 0.05869578623241978
Epoch 87, global_step 225000, average loss: 0.08446801885816967
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.9031
Valid loss 0.43046847204937544  -  Best loss 0.56046705064323 at step 220000
Epoch 87, global_step 225100, average loss: 0.08642115951421146
Epoch 87, global_step 225200, average loss: 0.050496141634430385
Epoch 88, global_step 225300, average loss: 0.0881118172758579
Epoch 88, global_step 225400, average loss: 0.016844717396306805
Epoch 88, global_step 225500, average loss: 0.016940408298760302
Epoch 88, global_step 225600, average loss: 0.047956244855668045
Epoch 88, global_step 225700, average loss: 0.04953611185810587
Epoch 88, global_step 225800, average loss: 0.06204916030481399
Epoch 88, global_step 225900, average loss: 0.09952100187358155
Epoch 88, global_step 226000, average loss: 0.07282606402739475
Epoch 88, global_step 226100, average loss: 0.08116560658221715
Epoch 88, global_step 226200, average loss: 0.07493147499204497
Epoch 88, global_step 226300, average loss: 0.046437886853018424
Epoch 88, global_step 226400, average loss: 0.08778907755178807
Epoch 88, global_step 226500, average loss: 0.05840030200939509
Epoch 88, global_step 226600, average loss: 0.033858071207650935
Epoch 88, global_step 226700, average loss: 0.05458938623240101
Epoch 88, global_step 226800, average loss: 0.03954078049915552
Epoch 88, global_step 226900, average loss: 0.11284501779002312
Epoch 88, global_step 227000, average loss: 0.06945183388823352
Epoch 88, global_step 227100, average loss: 0.05412589426894556
Epoch 88, global_step 227200, average loss: 0.06219762657878164
Epoch 88, global_step 227300, average loss: 0.0612488483737252
Epoch 88, global_step 227400, average loss: 0.036003027546830706
Epoch 88, global_step 227500, average loss: 0.07027581099908276
Epoch 88, global_step 227600, average loss: 0.029910897569643567
Epoch 88, global_step 227700, average loss: 0.05393960784705996
Epoch 88, global_step 227800, average loss: 0.07138467918892274
Epoch 89, global_step 227900, average loss: 0.05450197368620138
Epoch 89, global_step 228000, average loss: 0.023289800801867388
Epoch 89, global_step 228100, average loss: 0.02007087104138918
Epoch 89, global_step 228200, average loss: 0.045563265425371355
Epoch 89, global_step 228300, average loss: 0.0493071997059451
Epoch 89, global_step 228400, average loss: 0.06759130799568083
Epoch 89, global_step 228500, average loss: 0.047690524344143344
Epoch 89, global_step 228600, average loss: 0.06264100913176662
Epoch 89, global_step 228700, average loss: 0.05735452520049875
Epoch 89, global_step 228800, average loss: 0.04360323710374359
Epoch 89, global_step 228900, average loss: 0.08785124660105793
Epoch 89, global_step 229000, average loss: 0.09239817165143904
Epoch 89, global_step 229100, average loss: 0.0586864194800728
Epoch 89, global_step 229200, average loss: 0.13192602114868351
Epoch 89, global_step 229300, average loss: 0.04628493272735795
Epoch 89, global_step 229400, average loss: 0.03638019814665313
Epoch 89, global_step 229500, average loss: 0.03819429184797627
Epoch 89, global_step 229600, average loss: 0.07343922852502147
Epoch 89, global_step 229700, average loss: 0.05770969231125491
Epoch 89, global_step 229800, average loss: 0.053500703751706166
Epoch 89, global_step 229900, average loss: 0.028609724615380402
Epoch 89, global_step 230000, average loss: 0.04698629056241771
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8828
Valid loss 0.6401904370952463  -  Best loss 0.56046705064323 at step 220000
Epoch 89, global_step 230100, average loss: 0.07013460322930769
Epoch 89, global_step 230200, average loss: 0.07896593087709335
Epoch 89, global_step 230300, average loss: 0.08865790741110686
Epoch 89, global_step 230400, average loss: 0.0514844951905252
Epoch 90, global_step 230500, average loss: 0.027132272359740455
Epoch 90, global_step 230600, average loss: 0.038052514929077005
Epoch 90, global_step 230700, average loss: 0.03857225036947057
Epoch 90, global_step 230800, average loss: 0.07920343145364313
Epoch 90, global_step 230900, average loss: 0.03537797844110173
Epoch 90, global_step 231000, average loss: 0.06657998740018228
Epoch 90, global_step 231100, average loss: 0.05831343349374947
Epoch 90, global_step 231200, average loss: 0.05970011718090973
Epoch 90, global_step 231300, average loss: 0.03925132614829636
Epoch 90, global_step 231400, average loss: 0.07712261643260718
Epoch 90, global_step 231500, average loss: 0.061034414788373396
Epoch 90, global_step 231600, average loss: 0.08232728781484183
Epoch 90, global_step 231700, average loss: 0.059936179576179714
Epoch 90, global_step 231800, average loss: 0.08147647764599242
Epoch 90, global_step 231900, average loss: 0.08602732975487015
Epoch 90, global_step 232000, average loss: 0.08422480532775807
Epoch 90, global_step 232100, average loss: 0.11329825426357275
Epoch 90, global_step 232200, average loss: 0.03188997144869063
Epoch 90, global_step 232300, average loss: 0.05545576724078274
Epoch 90, global_step 232400, average loss: 0.08170825761844754
Epoch 90, global_step 232500, average loss: 0.06208668487728573
Epoch 90, global_step 232600, average loss: 0.05560592613976041
Epoch 90, global_step 232700, average loss: 0.09246841680913348
Epoch 90, global_step 232800, average loss: 0.05804481676132127
Epoch 90, global_step 232900, average loss: 0.08603825210651848
Epoch 91, global_step 233000, average loss: 0.05474856705230195
Epoch 91, global_step 233100, average loss: 0.03809027398470789
Epoch 91, global_step 233200, average loss: 0.0773924627260567
Epoch 91, global_step 233300, average loss: 0.08646475628011104
Epoch 91, global_step 233400, average loss: 0.03382850268506445
Epoch 91, global_step 233500, average loss: 0.09190309824021824
Epoch 91, global_step 233600, average loss: 0.05875602145395533
Epoch 91, global_step 233700, average loss: 0.04168898217503738
Epoch 91, global_step 233800, average loss: 0.07366581280693936
Epoch 91, global_step 233900, average loss: 0.053082948318406126
Epoch 91, global_step 234000, average loss: 0.05093475105917605
Epoch 91, global_step 234100, average loss: 0.03469383883202681
Epoch 91, global_step 234200, average loss: 0.05948776767560048
Epoch 91, global_step 234300, average loss: 0.03936357110811514
Epoch 91, global_step 234400, average loss: 0.05906981877677026
Epoch 91, global_step 234500, average loss: 0.05501286742874072
Epoch 91, global_step 234600, average loss: 0.07434696149648516
Epoch 91, global_step 234700, average loss: 0.06545133489235014
Epoch 91, global_step 234800, average loss: 0.06933310234788223
Epoch 91, global_step 234900, average loss: 0.07046738689619815
Epoch 91, global_step 235000, average loss: 0.04991126318403985
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.9068
Best model (step 235000, average valid loss 0.5332988036034567, average valid acc 0.9067708333333333) saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/best_model
Valid loss 0.5332988036034567  -  Best loss 0.5332988036034567 at step 235000
Epoch 91, global_step 235100, average loss: 0.0717323899584153
Epoch 91, global_step 235200, average loss: 0.07316371435314067
Epoch 91, global_step 235300, average loss: 0.06738129491022846
Epoch 91, global_step 235400, average loss: 0.03734483885782538
Epoch 91, global_step 235500, average loss: 0.0772297639388853
Epoch 92, global_step 235600, average loss: 0.12631205717363628
Epoch 92, global_step 235700, average loss: 0.049395931280450896
Epoch 92, global_step 235800, average loss: 0.04021915891804383
Epoch 92, global_step 235900, average loss: 0.08733526201467612
Epoch 92, global_step 236000, average loss: 0.03004408210515976
Epoch 92, global_step 236100, average loss: 0.08898661211198487
Epoch 92, global_step 236200, average loss: 0.054445780133537486
Epoch 92, global_step 236300, average loss: 0.0345262718781305
Epoch 92, global_step 236400, average loss: 0.09010361573666159
Epoch 92, global_step 236500, average loss: 0.028081204189147682
Epoch 92, global_step 236600, average loss: 0.04344408057324472
Epoch 92, global_step 236700, average loss: 0.07145863800753433
Epoch 92, global_step 236800, average loss: 0.09954397561770748
Epoch 92, global_step 236900, average loss: 0.10025101069644733
Epoch 92, global_step 237000, average loss: 0.06225273156036565
Epoch 92, global_step 237100, average loss: 0.07502476889843819
Epoch 92, global_step 237200, average loss: 0.021508116070181132
Epoch 92, global_step 237300, average loss: 0.0568169629163458
Epoch 92, global_step 237400, average loss: 0.05797688367783849
Epoch 92, global_step 237500, average loss: 0.03824164659206872
Epoch 92, global_step 237600, average loss: 0.04560530621849466
Epoch 92, global_step 237700, average loss: 0.030850076293281747
Epoch 92, global_step 237800, average loss: 0.03762206649596919
Epoch 92, global_step 237900, average loss: 0.04680720874646795
Epoch 92, global_step 238000, average loss: 0.046390065334780954
Epoch 93, global_step 238100, average loss: 0.03857044322241563
Epoch 93, global_step 238200, average loss: 0.03880612346831185
Epoch 93, global_step 238300, average loss: 0.03489553269602766
Epoch 93, global_step 238400, average loss: 0.052878051838924876
Epoch 93, global_step 238500, average loss: 0.08184692395312596
Epoch 93, global_step 238600, average loss: 0.04691740530419338
Epoch 93, global_step 238700, average loss: 0.08180353141789964
Epoch 93, global_step 238800, average loss: 0.05127830629433447
Epoch 93, global_step 238900, average loss: 0.06441205169794557
Epoch 93, global_step 239000, average loss: 0.04230586370147648
Epoch 93, global_step 239100, average loss: 0.09337183909956366
Epoch 93, global_step 239200, average loss: 0.03846778653998626
Epoch 93, global_step 239300, average loss: 0.04066726953307807
Epoch 93, global_step 239400, average loss: 0.04919587287033209
Epoch 93, global_step 239500, average loss: 0.0662141762398096
Epoch 93, global_step 239600, average loss: 0.06814485488459468
Epoch 93, global_step 239700, average loss: 0.012720703865052202
Epoch 93, global_step 239800, average loss: 0.05087171115657838
Epoch 93, global_step 239900, average loss: 0.09365536578676256
Epoch 93, global_step 240000, average loss: 0.10007278553770448
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8948
Valid loss 0.5949636072531466  -  Best loss 0.5332988036034567 at step 235000
Epoch 93, global_step 240100, average loss: 0.060162433130535646
Epoch 93, global_step 240200, average loss: 0.21886014333198545
Epoch 93, global_step 240300, average loss: 0.08690749122084526
Epoch 93, global_step 240400, average loss: 0.09841474419903534
Epoch 93, global_step 240500, average loss: 0.04778773948062735
Epoch 93, global_step 240600, average loss: 0.058526738424625364
Epoch 94, global_step 240700, average loss: 0.06200912691194389
Epoch 94, global_step 240800, average loss: 0.06002543074748246
Epoch 94, global_step 240900, average loss: 0.03398863019501732
Epoch 94, global_step 241000, average loss: 0.05115408158810169
Epoch 94, global_step 241100, average loss: 0.04576038397339289
Epoch 94, global_step 241200, average loss: 0.0870175249933527
Epoch 94, global_step 241300, average loss: 0.04339682626581634
Epoch 94, global_step 241400, average loss: 0.019256655260542176
Epoch 94, global_step 241500, average loss: 0.09175838169248891
Epoch 94, global_step 241600, average loss: 0.040275777118149565
Epoch 94, global_step 241700, average loss: 0.08306296654860489
Epoch 94, global_step 241800, average loss: 0.06199144831232843
Epoch 94, global_step 241900, average loss: 0.06058723269168695
Epoch 94, global_step 242000, average loss: 0.053124694646248825
Epoch 94, global_step 242100, average loss: 0.02530736173706828
Epoch 94, global_step 242200, average loss: 0.12288985781749943
Epoch 94, global_step 242300, average loss: 0.044425327266435485
Epoch 94, global_step 242400, average loss: 0.05456980881972413
Epoch 94, global_step 242500, average loss: 0.03419803280310589
Epoch 94, global_step 242600, average loss: 0.0686763383122161
Epoch 94, global_step 242700, average loss: 0.08091067103152455
Epoch 94, global_step 242800, average loss: 0.04005229909773334
Epoch 94, global_step 242900, average loss: 0.059775123691433694
Epoch 94, global_step 243000, average loss: 0.08266295527566399
Epoch 94, global_step 243100, average loss: 0.014965415017868508
Epoch 94, global_step 243200, average loss: 0.08775461413169978
Epoch 95, global_step 243300, average loss: 0.04017993353343627
Epoch 95, global_step 243400, average loss: 0.04188756627037946
Epoch 95, global_step 243500, average loss: 0.04424588042144023
Epoch 95, global_step 243600, average loss: 0.024633713649891434
Epoch 95, global_step 243700, average loss: 0.034617915946510036
Epoch 95, global_step 243800, average loss: 0.06510444363470015
Epoch 95, global_step 243900, average loss: 0.026697630425405804
Epoch 95, global_step 244000, average loss: 0.062230541785320385
Epoch 95, global_step 244100, average loss: 0.03080922871849907
Epoch 95, global_step 244200, average loss: 0.06583394932800729
Epoch 95, global_step 244300, average loss: 0.08182171431624738
Epoch 95, global_step 244400, average loss: 0.040494493195437825
Epoch 95, global_step 244500, average loss: 0.055229343077371595
Epoch 95, global_step 244600, average loss: 0.06818833396675472
Epoch 95, global_step 244700, average loss: 0.06260158592442167
Epoch 95, global_step 244800, average loss: 0.04088689379823336
Epoch 95, global_step 244900, average loss: 0.20088216809133883
Epoch 95, global_step 245000, average loss: 0.09831703062882298
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8812
Valid loss 0.524024043137757  -  Best loss 0.5332988036034567 at step 235000
Epoch 95, global_step 245100, average loss: 0.05369507336377865
Epoch 95, global_step 245200, average loss: 0.06472369150149461
Epoch 95, global_step 245300, average loss: 0.07805259443353861
Epoch 95, global_step 245400, average loss: 0.03502488397869456
Epoch 95, global_step 245500, average loss: 0.023219779373321217
Epoch 95, global_step 245600, average loss: 0.08761295367250568
Epoch 95, global_step 245700, average loss: 0.0689244382661127
Epoch 96, global_step 245800, average loss: 0.03723509178569657
Epoch 96, global_step 245900, average loss: 0.02963306966943492
Epoch 96, global_step 246000, average loss: 0.03278746547708579
Epoch 96, global_step 246100, average loss: 0.02256525674376462
Epoch 96, global_step 246200, average loss: 0.0651032606085937
Epoch 96, global_step 246300, average loss: 0.07128551657617209
Epoch 96, global_step 246400, average loss: 0.05771688888620702
Epoch 96, global_step 246500, average loss: 0.08957813068293036
Epoch 96, global_step 246600, average loss: 0.061705059024243385
Epoch 96, global_step 246700, average loss: 0.05740792294032872
Epoch 96, global_step 246800, average loss: 0.030735185224475572
Epoch 96, global_step 246900, average loss: 0.0636488406141143
Epoch 96, global_step 247000, average loss: 0.050540274191080245
Epoch 96, global_step 247100, average loss: 0.034343195385590664
Epoch 96, global_step 247200, average loss: 0.03358468121048645
Epoch 96, global_step 247300, average loss: 0.07726591161146644
Epoch 96, global_step 247400, average loss: 0.05159474785497878
Epoch 96, global_step 247500, average loss: 0.030780069855682088
Epoch 96, global_step 247600, average loss: 0.04520404393042554
Epoch 96, global_step 247700, average loss: 0.03888854273027391
Epoch 96, global_step 247800, average loss: 0.0322749981142988
Epoch 96, global_step 247900, average loss: 0.10610903504959424
Epoch 96, global_step 248000, average loss: 0.09254449551182915
Epoch 96, global_step 248100, average loss: 0.05268322888608964
Epoch 96, global_step 248200, average loss: 0.060971860760910206
Epoch 96, global_step 248300, average loss: 0.052276839615078646
Epoch 97, global_step 248400, average loss: 0.02223314976421534
Epoch 97, global_step 248500, average loss: 0.05088709868869046
Epoch 97, global_step 248600, average loss: 0.07332652304852673
Epoch 97, global_step 248700, average loss: 0.08560473388643004
Epoch 97, global_step 248800, average loss: 0.023581717824854423
Epoch 97, global_step 248900, average loss: 0.04501692430661933
Epoch 97, global_step 249000, average loss: 0.04213884738383058
Epoch 97, global_step 249100, average loss: 0.06505835952208144
Epoch 97, global_step 249200, average loss: 0.07677412304255996
Epoch 97, global_step 249300, average loss: 0.07165848666365492
Epoch 97, global_step 249400, average loss: 0.0648950123711984
Epoch 97, global_step 249500, average loss: 0.046098850660564496
Epoch 97, global_step 249600, average loss: 0.01722545458826062
Epoch 97, global_step 249700, average loss: 0.028526514186742135
Epoch 97, global_step 249800, average loss: 0.056957452576389185
Epoch 97, global_step 249900, average loss: 0.06982664743452915
Epoch 97, global_step 250000, average loss: 0.04998845138805336
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.8870
Valid loss 0.6021484068203623  -  Best loss 0.5332988036034567 at step 235000
Epoch 97, global_step 250100, average loss: 0.06457353277823132
Epoch 97, global_step 250200, average loss: 0.07899508022172086
Epoch 97, global_step 250300, average loss: 0.19201809893020255
Epoch 97, global_step 250400, average loss: 0.057469168224342865
Epoch 97, global_step 250500, average loss: 0.04773021888358926
Epoch 97, global_step 250600, average loss: 0.062305105043342336
Epoch 97, global_step 250700, average loss: 0.030548424075168442
Epoch 97, global_step 250800, average loss: 0.04481947239408328
Epoch 98, global_step 250900, average loss: 0.03913144567857671
Epoch 98, global_step 251000, average loss: 0.03713888492449769
Epoch 98, global_step 251100, average loss: 0.07009080124895263
Epoch 98, global_step 251200, average loss: 0.04795642050019524
Epoch 98, global_step 251300, average loss: 0.04248844669571554
Epoch 98, global_step 251400, average loss: 0.05750349548099621
Epoch 98, global_step 251500, average loss: 0.07018356359978498
Epoch 98, global_step 251600, average loss: 0.053842650058068105
Epoch 98, global_step 251700, average loss: 0.05390884859349171
Epoch 98, global_step 251800, average loss: 0.0269977441921219
Epoch 98, global_step 251900, average loss: 0.025079368409642484
Epoch 98, global_step 252000, average loss: 0.02068680225413118
Epoch 98, global_step 252100, average loss: 0.0371640444908553
Epoch 98, global_step 252200, average loss: 0.03428658394499507
Epoch 98, global_step 252300, average loss: 0.034333521917360485
Epoch 98, global_step 252400, average loss: 0.02603791742447356
Epoch 98, global_step 252500, average loss: 0.0692616372271732
Epoch 98, global_step 252600, average loss: 0.05202324171470536
Epoch 98, global_step 252700, average loss: 0.04752050693896308
Epoch 98, global_step 252800, average loss: 0.041093503519077784
Epoch 98, global_step 252900, average loss: 0.07711066434072564
Epoch 98, global_step 253000, average loss: 0.03699178080336424
Epoch 98, global_step 253100, average loss: 0.10288005149865058
Epoch 98, global_step 253200, average loss: 0.05434065996647405
Epoch 98, global_step 253300, average loss: 0.02033542898432643
Epoch 98, global_step 253400, average loss: 0.07816816808248404
Epoch 99, global_step 253500, average loss: 0.02496628496592166
Epoch 99, global_step 253600, average loss: 0.03767010520867189
Epoch 99, global_step 253700, average loss: 0.052987376240926094
Epoch 99, global_step 253800, average loss: 0.01134484395995969
Epoch 99, global_step 253900, average loss: 0.037209595805034044
Epoch 99, global_step 254000, average loss: 0.028369736888998888
Epoch 99, global_step 254100, average loss: 0.07021916414953011
Epoch 99, global_step 254200, average loss: 0.05945693266512535
Epoch 99, global_step 254300, average loss: 0.04830024184790091
Epoch 99, global_step 254400, average loss: 0.04474561368857394
Epoch 99, global_step 254500, average loss: 0.04198423421745247
Epoch 99, global_step 254600, average loss: 0.033018545271188485
Epoch 99, global_step 254700, average loss: 0.031588859567200415
Epoch 99, global_step 254800, average loss: 0.05565529685853107
Epoch 99, global_step 254900, average loss: 0.03593205625184055
Epoch 99, global_step 255000, average loss: 0.09179934614257945
Checkpoint saved at data/ft_plms/llama_base_low_rank/freeze_plm_False/epochs_100_lr_0.0001_rank_32_ts_1755590201.391309/checkpoint
Validation accuracy: 0.9026
Valid loss 0.45887430037486904  -  Best loss 0.5332988036034567 at step 235000
Epoch 99, global_step 255100, average loss: 0.021871129419087084
Epoch 99, global_step 255200, average loss: 0.02509394369197253
Epoch 99, global_step 255300, average loss: 0.13238468927171199
Epoch 99, global_step 255400, average loss: 0.0549131902812951
Epoch 99, global_step 255500, average loss: 0.020036564338661265
Epoch 99, global_step 255600, average loss: 0.05334095046375296
Epoch 99, global_step 255700, average loss: 0.056232012694890726
Epoch 99, global_step 255800, average loss: 0.05597404168642242
Epoch 99, global_step 255900, average loss: 0.04824366281187395
Epoch 99, global_step 256000, average loss: 0.03434812302504724
Done adaptation, average training loss = 0.15857508079863844
